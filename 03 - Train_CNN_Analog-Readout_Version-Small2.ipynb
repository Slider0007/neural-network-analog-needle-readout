{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to extract the needle position of an analog needle device.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFlite_Version  = \"1300\"   \n",
    "TFlite_MainType = \"ana-cont\"\n",
    "TFlite_Size     = \"s2\"\n",
    "Training_Percentage = 0.05              # 0.0 = Use all Images for Training\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "## 2024-03-30: Code adapted to TF 2.16####################################\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History \n",
    "import math\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Picture size must be 32x32 with 3 color channels (RGB)\n",
    "* The filename contains the informations needed for training in the first 3 digits::\n",
    "* Typical filename: \n",
    "    * x.y-zzzz.jpg \n",
    "    * e.g. \"4.6_Lfd-1406_zeiger3_2019-06-02T050011\"\n",
    "\n",
    "|Place holder | Meaning                     | Usage        |\n",
    "|------------- |-----------------------------|--------------|\n",
    "| **x.y**          | readout value               | **to be learned** |\n",
    "| zzzz        | additional information              | not needed   |\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected output for each image in the corresponding y_data[]\n",
    "    * The periodic nature is reflected in a **sin/cos coding**, which allows to restore the angle/counter value with an arctan later on.\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) as the filenames are on order due to the encoding of the expected analog readout in the filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1739, 32, 32, 3)\n",
      "(1739, 2)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='data_resize_all'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    test_image = np.reshape(test_image, (32,32,3))\n",
    "    base = os.path.basename(aktfile)\n",
    "    target_number = (float(base[0:3])) / 10\n",
    "    target_sin = math.sin(target_number * math.pi * 2)\n",
    "    target_cos = math.cos(target_number * math.pi * 2)\n",
    "\n",
    "    x_data.append(test_image)\n",
    "    zw = np.array([target_sin, target_cos])\n",
    "    y_data.append(zw)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 32, 3)\n",
    "* Shape of the output layer: (2) - sin and cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │            \u001b[38;5;34m12\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │        \u001b[38;5;34m12,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,798</span> (174.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,798\u001b[0m (174.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,792</span> (174.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,792\u001b[0m (174.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (24.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6\u001b[0m (24.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "inputs2 = tf.keras.layers.BatchNormalization()(inputs)\n",
    "inputs3 = tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation=\"relu\")(inputs2)\n",
    "inputs4 = tf.keras.layers.MaxPool2D(pool_size=(4,4))(inputs3)\n",
    "inputs5 = tf.keras.layers.Conv2D(16, (5, 5), padding='same', activation=\"relu\")(inputs4)\n",
    "inputs6 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs5)\n",
    "inputs7 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\")(inputs6)\n",
    "inputs8 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs7)\n",
    "inputs9 = tf.keras.layers.Flatten()(inputs8)\n",
    "inputs10 = tf.keras.layers.Dense(128,activation=\"relu\")(inputs9)\n",
    "inputs11 = tf.keras.layers.Dense(64,activation=\"relu\")(inputs10)\n",
    "output = tf.keras.layers.Dense(2)(inputs11)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(loss=keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness and pixel shift variations. These is implemented with a ImageDataGenerator.\n",
    "\n",
    "\n",
    "The training is splitted into two steps:\n",
    "1. Variation of the brightness only\n",
    "2. Variation of brightness and Pixel Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Brigthness scattering only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 41/218\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5233 - loss: 0.5301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muell\\anaconda3\\envs\\py311-tf216-opencv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5383 - loss: 0.5049 - val_accuracy: 0.6897 - val_loss: 0.3257\n",
      "Epoch 2/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7489 - loss: 0.2985 - val_accuracy: 0.8966 - val_loss: 0.1359\n",
      "Epoch 3/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.1226 - val_accuracy: 0.9080 - val_loss: 0.0622\n",
      "Epoch 4/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.0742 - val_accuracy: 0.9425 - val_loss: 0.0622\n",
      "Epoch 5/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.0473 - val_accuracy: 0.9540 - val_loss: 0.0217\n",
      "Epoch 6/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.0374 - val_accuracy: 0.9540 - val_loss: 0.0322\n",
      "Epoch 7/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0240 - val_accuracy: 0.8966 - val_loss: 0.0922\n",
      "Epoch 8/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.0249 - val_accuracy: 0.9655 - val_loss: 0.0129\n",
      "Epoch 9/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0149 - val_accuracy: 0.9540 - val_loss: 0.0141\n",
      "Epoch 10/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.0136 - val_accuracy: 0.9655 - val_loss: 0.0082\n",
      "Epoch 11/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.0120 - val_accuracy: 0.9655 - val_loss: 0.0170\n",
      "Epoch 12/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0128 - val_accuracy: 0.9655 - val_loss: 0.0102\n",
      "Epoch 13/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0092 - val_accuracy: 0.9655 - val_loss: 0.0081\n",
      "Epoch 14/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0078 - val_accuracy: 0.9885 - val_loss: 0.0061\n",
      "Epoch 15/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0094 - val_accuracy: 0.9770 - val_loss: 0.0093\n",
      "Epoch 16/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0069 - val_accuracy: 0.9655 - val_loss: 0.0125\n",
      "Epoch 17/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0073 - val_accuracy: 0.9885 - val_loss: 0.0052\n",
      "Epoch 18/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0050 - val_accuracy: 0.9770 - val_loss: 0.0078\n",
      "Epoch 19/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0056 - val_accuracy: 0.9885 - val_loss: 0.0068\n",
      "Epoch 20/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0054 - val_accuracy: 0.9885 - val_loss: 0.0051\n",
      "Epoch 21/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0057 - val_accuracy: 0.9770 - val_loss: 0.0094\n",
      "Epoch 22/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0043 - val_accuracy: 0.9770 - val_loss: 0.0031\n",
      "Epoch 23/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0050 - val_accuracy: 0.9885 - val_loss: 0.0057\n",
      "Epoch 24/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.0038 - val_accuracy: 0.9655 - val_loss: 0.0025\n",
      "Epoch 25/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0037 - val_accuracy: 0.9770 - val_loss: 0.0047\n",
      "Epoch 26/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0038 - val_accuracy: 0.9770 - val_loss: 0.0028\n",
      "Epoch 27/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0036 - val_accuracy: 0.9770 - val_loss: 0.0029\n",
      "Epoch 28/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 29/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 30/30\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 30\n",
    "Shift_Range = 0\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(val_loss_ges)\n",
    "\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Brigthness and Pixel Shift scattering\n",
    "Here a higher number of epochs is used to reach the minimum loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7114 - loss: 0.3507 - val_accuracy: 0.8851 - val_loss: 0.1360\n",
      "Epoch 2/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8718 - loss: 0.1377 - val_accuracy: 0.8966 - val_loss: 0.0787\n",
      "Epoch 3/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.0777 - val_accuracy: 0.9425 - val_loss: 0.0730\n",
      "Epoch 4/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9355 - loss: 0.0548 - val_accuracy: 0.9310 - val_loss: 0.0627\n",
      "Epoch 5/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.0574 - val_accuracy: 0.9540 - val_loss: 0.0454\n",
      "Epoch 6/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.0460 - val_accuracy: 0.9425 - val_loss: 0.0398\n",
      "Epoch 7/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.0362 - val_accuracy: 0.9770 - val_loss: 0.0250\n",
      "Epoch 8/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.0453 - val_accuracy: 0.9080 - val_loss: 0.0322\n",
      "Epoch 9/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9459 - loss: 0.0299 - val_accuracy: 0.9425 - val_loss: 0.0267\n",
      "Epoch 10/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.0248 - val_accuracy: 0.9425 - val_loss: 0.0326\n",
      "Epoch 11/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9608 - loss: 0.0229 - val_accuracy: 0.9655 - val_loss: 0.0192\n",
      "Epoch 12/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0171\n",
      "Epoch 13/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9603 - loss: 0.0175 - val_accuracy: 0.9885 - val_loss: 0.0157\n",
      "Epoch 14/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9634 - loss: 0.0162 - val_accuracy: 0.9770 - val_loss: 0.0126\n",
      "Epoch 15/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9672 - loss: 0.0151 - val_accuracy: 0.9540 - val_loss: 0.0140\n",
      "Epoch 16/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9618 - loss: 0.0141 - val_accuracy: 0.9770 - val_loss: 0.0134\n",
      "Epoch 17/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.0147 - val_accuracy: 0.9770 - val_loss: 0.0088\n",
      "Epoch 18/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0142 - val_accuracy: 0.9655 - val_loss: 0.0130\n",
      "Epoch 19/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0128 - val_accuracy: 0.9770 - val_loss: 0.0094\n",
      "Epoch 20/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0105 - val_accuracy: 0.9770 - val_loss: 0.0086\n",
      "Epoch 21/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
      "Epoch 22/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9690 - loss: 0.0114 - val_accuracy: 0.9770 - val_loss: 0.0039\n",
      "Epoch 23/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0087 - val_accuracy: 0.9655 - val_loss: 0.0092\n",
      "Epoch 24/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9703 - loss: 0.0087 - val_accuracy: 0.9655 - val_loss: 0.0087\n",
      "Epoch 25/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0106 - val_accuracy: 0.9540 - val_loss: 0.0063\n",
      "Epoch 26/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9737 - loss: 0.0091 - val_accuracy: 0.9540 - val_loss: 0.0073\n",
      "Epoch 27/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.0092 - val_accuracy: 0.9885 - val_loss: 0.0061\n",
      "Epoch 28/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0095 - val_accuracy: 0.9655 - val_loss: 0.0145\n",
      "Epoch 29/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0092 - val_accuracy: 0.9540 - val_loss: 0.0114\n",
      "Epoch 30/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9678 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 31/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.0073 - val_accuracy: 0.9770 - val_loss: 0.0033\n",
      "Epoch 32/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0064 - val_accuracy: 0.9655 - val_loss: 0.0081\n",
      "Epoch 33/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9746 - loss: 0.0058 - val_accuracy: 0.9770 - val_loss: 0.0061\n",
      "Epoch 34/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0069 - val_accuracy: 0.9540 - val_loss: 0.0148\n",
      "Epoch 35/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0075 - val_accuracy: 0.9770 - val_loss: 0.0052\n",
      "Epoch 36/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.0052 - val_accuracy: 0.9540 - val_loss: 0.0075\n",
      "Epoch 37/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0060 - val_accuracy: 0.9770 - val_loss: 0.0039\n",
      "Epoch 38/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0060 - val_accuracy: 0.9540 - val_loss: 0.0059\n",
      "Epoch 39/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 40/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0047 - val_accuracy: 0.9655 - val_loss: 0.0067\n",
      "Epoch 41/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9765 - loss: 0.0062 - val_accuracy: 0.9655 - val_loss: 0.0039\n",
      "Epoch 42/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9705 - loss: 0.0057 - val_accuracy: 0.9885 - val_loss: 0.0057\n",
      "Epoch 43/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0055 - val_accuracy: 0.9540 - val_loss: 0.0053\n",
      "Epoch 44/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.0052 - val_accuracy: 0.9540 - val_loss: 0.0042\n",
      "Epoch 45/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9809 - loss: 0.0053 - val_accuracy: 0.9885 - val_loss: 0.0044\n",
      "Epoch 46/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9704 - loss: 0.0056 - val_accuracy: 0.9540 - val_loss: 0.0077\n",
      "Epoch 47/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.0050 - val_accuracy: 0.9885 - val_loss: 0.0037\n",
      "Epoch 48/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0051 - val_accuracy: 0.9770 - val_loss: 0.0044\n",
      "Epoch 49/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0057 - val_accuracy: 0.9885 - val_loss: 0.0045\n",
      "Epoch 50/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0057 - val_accuracy: 0.9770 - val_loss: 0.0052\n",
      "Epoch 51/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.0055 - val_accuracy: 0.9770 - val_loss: 0.0057\n",
      "Epoch 52/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9787 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0044 - val_accuracy: 0.9885 - val_loss: 0.0052\n",
      "Epoch 54/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0041 - val_accuracy: 0.9655 - val_loss: 0.0055\n",
      "Epoch 55/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9759 - loss: 0.0070 - val_accuracy: 0.9885 - val_loss: 0.0051\n",
      "Epoch 56/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0046 - val_accuracy: 0.9770 - val_loss: 0.0029\n",
      "Epoch 57/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0038 - val_accuracy: 0.9885 - val_loss: 0.0049\n",
      "Epoch 58/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0041 - val_accuracy: 0.9885 - val_loss: 0.0030\n",
      "Epoch 59/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9684 - loss: 0.0049 - val_accuracy: 0.9770 - val_loss: 0.0036\n",
      "Epoch 60/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.0046 - val_accuracy: 0.9655 - val_loss: 0.0026\n",
      "Epoch 61/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.0046 - val_accuracy: 0.9885 - val_loss: 0.0049\n",
      "Epoch 62/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0036 - val_accuracy: 0.9310 - val_loss: 0.0036\n",
      "Epoch 63/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9809 - loss: 0.0042 - val_accuracy: 0.9655 - val_loss: 0.0045\n",
      "Epoch 64/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9810 - loss: 0.0033 - val_accuracy: 0.9770 - val_loss: 0.0035\n",
      "Epoch 65/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0040 - val_accuracy: 0.9655 - val_loss: 0.0035\n",
      "Epoch 66/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0044 - val_accuracy: 0.9885 - val_loss: 0.0047\n",
      "Epoch 67/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0044 - val_accuracy: 0.9540 - val_loss: 0.0047\n",
      "Epoch 68/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 69/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9835 - loss: 0.0037 - val_accuracy: 0.9655 - val_loss: 0.0028\n",
      "Epoch 70/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9769 - loss: 0.0041 - val_accuracy: 0.9540 - val_loss: 0.0061\n",
      "Epoch 71/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9758 - loss: 0.0033 - val_accuracy: 0.9770 - val_loss: 0.0059\n",
      "Epoch 72/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0032 - val_accuracy: 0.9885 - val_loss: 0.0029\n",
      "Epoch 73/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0033 - val_accuracy: 0.9885 - val_loss: 0.0028\n",
      "Epoch 74/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9830 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 75/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 76/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9838 - loss: 0.0034 - val_accuracy: 0.9655 - val_loss: 0.0026\n",
      "Epoch 77/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 78/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9855 - loss: 0.0028 - val_accuracy: 0.9885 - val_loss: 0.0046\n",
      "Epoch 79/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0031 - val_accuracy: 0.9885 - val_loss: 0.0046\n",
      "Epoch 80/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0034 - val_accuracy: 0.9540 - val_loss: 0.0026\n",
      "Epoch 81/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0034 - val_accuracy: 0.9885 - val_loss: 0.0029\n",
      "Epoch 82/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0026 - val_accuracy: 0.9885 - val_loss: 0.0022\n",
      "Epoch 83/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0033 - val_accuracy: 0.9885 - val_loss: 0.0027\n",
      "Epoch 84/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.0029 - val_accuracy: 0.9770 - val_loss: 0.0019\n",
      "Epoch 85/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9822 - loss: 0.0025 - val_accuracy: 0.9885 - val_loss: 0.0022\n",
      "Epoch 86/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0032 - val_accuracy: 0.9885 - val_loss: 0.0040\n",
      "Epoch 87/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9802 - loss: 0.0027 - val_accuracy: 0.9885 - val_loss: 0.0022\n",
      "Epoch 88/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0030 - val_accuracy: 0.9770 - val_loss: 0.0031\n",
      "Epoch 89/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.0030 - val_accuracy: 0.9770 - val_loss: 0.0028\n",
      "Epoch 90/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.0023 - val_accuracy: 0.9885 - val_loss: 0.0027\n",
      "Epoch 91/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9885 - loss: 0.0026 - val_accuracy: 0.9770 - val_loss: 0.0025\n",
      "Epoch 92/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0035 - val_accuracy: 0.9770 - val_loss: 0.0018\n",
      "Epoch 93/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0022 - val_accuracy: 0.9770 - val_loss: 0.0028\n",
      "Epoch 94/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.0024 - val_accuracy: 0.9770 - val_loss: 0.0017\n",
      "Epoch 95/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 96/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9788 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 97/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.0028 - val_accuracy: 0.9770 - val_loss: 0.0018\n",
      "Epoch 98/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.0022 - val_accuracy: 0.9885 - val_loss: 0.0032\n",
      "Epoch 99/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 100/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0023 - val_accuracy: 0.9655 - val_loss: 0.0021\n",
      "Epoch 101/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 102/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0023 - val_accuracy: 0.9655 - val_loss: 0.0025\n",
      "Epoch 103/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 104/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0023 - val_accuracy: 0.9770 - val_loss: 0.0017\n",
      "Epoch 105/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0021 - val_accuracy: 0.9655 - val_loss: 0.0024\n",
      "Epoch 106/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0024 - val_accuracy: 0.9770 - val_loss: 0.0034\n",
      "Epoch 107/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0020 - val_accuracy: 0.9885 - val_loss: 0.0026\n",
      "Epoch 108/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9784 - loss: 0.0023 - val_accuracy: 0.9885 - val_loss: 0.0018\n",
      "Epoch 109/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0021 - val_accuracy: 0.9770 - val_loss: 0.0020\n",
      "Epoch 110/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0024 - val_accuracy: 0.9885 - val_loss: 0.0023\n",
      "Epoch 111/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9864 - loss: 0.0022 - val_accuracy: 0.9885 - val_loss: 0.0020\n",
      "Epoch 112/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0021 - val_accuracy: 0.9885 - val_loss: 0.0015\n",
      "Epoch 113/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9890 - loss: 0.0021 - val_accuracy: 0.9655 - val_loss: 0.0020\n",
      "Epoch 114/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 115/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0019 - val_accuracy: 0.9885 - val_loss: 0.0019\n",
      "Epoch 116/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0024 - val_accuracy: 0.9885 - val_loss: 0.0019\n",
      "Epoch 117/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.0019 - val_accuracy: 0.9885 - val_loss: 0.0019\n",
      "Epoch 118/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0022 - val_accuracy: 0.9885 - val_loss: 0.0015\n",
      "Epoch 119/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 120/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0018 - val_accuracy: 0.9770 - val_loss: 0.0025\n",
      "Epoch 121/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.0022 - val_accuracy: 0.9655 - val_loss: 0.0035\n",
      "Epoch 122/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0020 - val_accuracy: 0.9770 - val_loss: 0.0016\n",
      "Epoch 123/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9776 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 124/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0020 - val_accuracy: 0.9655 - val_loss: 9.9661e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 126/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9830 - loss: 0.0018 - val_accuracy: 0.9770 - val_loss: 0.0021\n",
      "Epoch 127/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9888 - loss: 0.0019 - val_accuracy: 0.9885 - val_loss: 0.0022\n",
      "Epoch 128/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 130/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0019\n",
      "Epoch 131/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0019 - val_accuracy: 0.9885 - val_loss: 0.0015\n",
      "Epoch 132/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0022\n",
      "Epoch 133/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0017 - val_accuracy: 0.9770 - val_loss: 0.0018\n",
      "Epoch 135/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0016 - val_accuracy: 0.9885 - val_loss: 0.0018\n",
      "Epoch 136/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.0017 - val_accuracy: 0.9770 - val_loss: 0.0022\n",
      "Epoch 137/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0017 - val_accuracy: 0.9770 - val_loss: 0.0014\n",
      "Epoch 138/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0023 - val_accuracy: 0.9885 - val_loss: 0.0017\n",
      "Epoch 139/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 140/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0018 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 141/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.0016 - val_accuracy: 0.9885 - val_loss: 0.0015\n",
      "Epoch 142/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 143/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 144/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0016 - val_accuracy: 0.9885 - val_loss: 0.0019\n",
      "Epoch 145/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0015 - val_accuracy: 0.9885 - val_loss: 0.0018\n",
      "Epoch 146/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 147/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0014\n",
      "Epoch 148/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0013\n",
      "Epoch 149/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0013\n",
      "Epoch 150/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0018 - val_accuracy: 0.9885 - val_loss: 0.0014\n",
      "Epoch 151/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9876 - loss: 0.0019 - val_accuracy: 0.9770 - val_loss: 0.0013\n",
      "Epoch 152/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 153/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0014 - val_accuracy: 0.9655 - val_loss: 0.0015\n",
      "Epoch 154/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 155/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0020 - val_accuracy: 0.9885 - val_loss: 0.0017\n",
      "Epoch 156/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 157/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 158/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0015 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 159/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.0014 - val_accuracy: 0.9885 - val_loss: 0.0016\n",
      "Epoch 160/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.0015\n",
      "Epoch 161/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0014\n",
      "Epoch 162/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0020 - val_accuracy: 0.9885 - val_loss: 0.0013\n",
      "Epoch 163/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 8.8989e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0014 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 165/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0013 - val_accuracy: 0.9770 - val_loss: 0.0012\n",
      "Epoch 166/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 9.9103e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 168/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 169/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9850 - loss: 0.0014 - val_accuracy: 0.9885 - val_loss: 0.0015\n",
      "Epoch 170/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0017 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 171/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0015 - val_accuracy: 0.9770 - val_loss: 0.0015\n",
      "Epoch 172/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 173/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0016 - val_accuracy: 0.9770 - val_loss: 0.0013\n",
      "Epoch 174/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0014 - val_accuracy: 0.9655 - val_loss: 0.0011\n",
      "Epoch 175/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0011 - val_accuracy: 0.9770 - val_loss: 0.0033\n",
      "Epoch 176/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 177/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 178/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0016 - val_accuracy: 0.9885 - val_loss: 0.0010\n",
      "Epoch 179/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0014 - val_accuracy: 0.9885 - val_loss: 0.0016\n",
      "Epoch 180/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0015 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 181/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0013 - val_accuracy: 0.9885 - val_loss: 0.0021\n",
      "Epoch 182/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0013 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 183/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9939 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 8.8295e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0015 - val_accuracy: 0.9770 - val_loss: 9.6851e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0014 - val_accuracy: 0.9770 - val_loss: 0.0019\n",
      "Epoch 186/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0013 - val_accuracy: 0.9770 - val_loss: 0.0012\n",
      "Epoch 187/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 8.6663e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 189/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0012 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 190/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.0013 - val_accuracy: 0.9770 - val_loss: 0.0013\n",
      "Epoch 191/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 192/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 193/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0014 - val_accuracy: 0.9885 - val_loss: 0.0014\n",
      "Epoch 194/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 9.5950e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 0.0016\n",
      "Epoch 196/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 9.4874e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 198/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 9.3728e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 8.7937e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0013 - val_accuracy: 0.9770 - val_loss: 0.0013\n",
      "Epoch 201/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0014 - val_accuracy: 0.9885 - val_loss: 8.1628e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 9.8585e-04 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 203/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 9.0658e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 9.8009e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 205/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0012 - val_accuracy: 0.9885 - val_loss: 7.0668e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 207/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0011 - val_accuracy: 0.9770 - val_loss: 0.0012\n",
      "Epoch 208/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 209/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 7.6506e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.1302e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 212/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 9.8896e-04 - val_accuracy: 0.9885 - val_loss: 8.8623e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0011 - val_accuracy: 0.9770 - val_loss: 7.9862e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0012 - val_accuracy: 0.9885 - val_loss: 0.0010\n",
      "Epoch 215/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0012 - val_accuracy: 0.9655 - val_loss: 8.0919e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0012 - val_accuracy: 0.9770 - val_loss: 8.4679e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 9.5629e-04 - val_accuracy: 0.9885 - val_loss: 9.0092e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0011 - val_accuracy: 0.9770 - val_loss: 8.6552e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 220/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0011 - val_accuracy: 0.9770 - val_loss: 0.0012\n",
      "Epoch 221/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 9.0425e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0010 - val_accuracy: 0.9885 - val_loss: 9.7249e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.0011 - val_accuracy: 0.9770 - val_loss: 0.0014\n",
      "Epoch 224/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.2950e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0010 - val_accuracy: 0.9885 - val_loss: 6.2259e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 9.0506e-04 - val_accuracy: 0.9770 - val_loss: 7.1474e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 9.6452e-04 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 228/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 9.6913e-04 - val_accuracy: 0.9885 - val_loss: 0.0010\n",
      "Epoch 229/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 9.8952e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 231/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 232/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 233/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 7.6264e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.8791e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 9.4382e-04 - val_accuracy: 1.0000 - val_loss: 6.7514e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.0013 - val_accuracy: 0.9885 - val_loss: 9.3449e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 9.3972e-04 - val_accuracy: 0.9655 - val_loss: 8.7290e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.1843e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0010 - val_accuracy: 0.9770 - val_loss: 7.7935e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 9.8542e-04 - val_accuracy: 0.9770 - val_loss: 8.5203e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0011 - val_accuracy: 0.9885 - val_loss: 7.3658e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 9.0024e-04 - val_accuracy: 0.9885 - val_loss: 8.2399e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0010 - val_accuracy: 0.9885 - val_loss: 7.8918e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 9.1121e-04 - val_accuracy: 0.9885 - val_loss: 8.2400e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 9.0638e-04 - val_accuracy: 0.9885 - val_loss: 6.6980e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 8.7518e-04 - val_accuracy: 0.9885 - val_loss: 9.5346e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0010 - val_accuracy: 0.9885 - val_loss: 6.9845e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 8.7809e-04 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 249/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 8.3932e-04 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 250/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 9.4577e-04 - val_accuracy: 1.0000 - val_loss: 5.4011e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 9.4001e-04 - val_accuracy: 1.0000 - val_loss: 7.5942e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 7.8934e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 8.9882e-04 - val_accuracy: 0.9770 - val_loss: 9.3218e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 9.2573e-04 - val_accuracy: 1.0000 - val_loss: 7.3275e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 8.2303e-04 - val_accuracy: 0.9885 - val_loss: 5.4043e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 9.3408e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 257/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 8.8354e-04 - val_accuracy: 0.9770 - val_loss: 7.5163e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 8.3677e-04 - val_accuracy: 0.9885 - val_loss: 6.8823e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 9.0890e-04 - val_accuracy: 0.9885 - val_loss: 0.0010\n",
      "Epoch 260/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 9.1826e-04 - val_accuracy: 1.0000 - val_loss: 7.1593e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 8.3884e-04 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 262/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 9.0946e-04 - val_accuracy: 1.0000 - val_loss: 7.2467e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 8.5208e-04 - val_accuracy: 0.9885 - val_loss: 0.0011\n",
      "Epoch 264/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 9.3617e-04 - val_accuracy: 0.9885 - val_loss: 8.4313e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 8.8620e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 266/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 9.6209e-04 - val_accuracy: 1.0000 - val_loss: 5.9627e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 8.5597e-04 - val_accuracy: 0.9885 - val_loss: 5.4875e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 7.9574e-04 - val_accuracy: 0.9770 - val_loss: 6.0788e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 8.3122e-04 - val_accuracy: 0.9770 - val_loss: 9.6944e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 8.6850e-04 - val_accuracy: 1.0000 - val_loss: 7.4577e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 8.4303e-04 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 272/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 9.1454e-04 - val_accuracy: 1.0000 - val_loss: 4.3174e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 7.5023e-04 - val_accuracy: 0.9885 - val_loss: 5.8617e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 7.6872e-04 - val_accuracy: 1.0000 - val_loss: 8.0284e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9816 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 9.4248e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 8.1808e-04 - val_accuracy: 0.9885 - val_loss: 5.6248e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 8.1954e-04 - val_accuracy: 0.9885 - val_loss: 6.9449e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 8.2561e-04 - val_accuracy: 0.9885 - val_loss: 7.7510e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 8.9868e-04 - val_accuracy: 1.0000 - val_loss: 7.7983e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 9.1424e-04 - val_accuracy: 1.0000 - val_loss: 5.1634e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 7.8297e-04 - val_accuracy: 0.9655 - val_loss: 5.5173e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 7.7699e-04 - val_accuracy: 0.9885 - val_loss: 9.1789e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 7.7968e-04 - val_accuracy: 0.9885 - val_loss: 6.8660e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 7.5931e-04 - val_accuracy: 1.0000 - val_loss: 6.3248e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 9.0076e-04 - val_accuracy: 0.9770 - val_loss: 9.2022e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9902 - loss: 7.9744e-04 - val_accuracy: 1.0000 - val_loss: 5.1955e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 7.2101e-04 - val_accuracy: 0.9885 - val_loss: 5.8109e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 9.3248e-04 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 289/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9888 - loss: 7.8337e-04 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 290/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 8.3957e-04 - val_accuracy: 0.9885 - val_loss: 7.6250e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 7.6988e-04 - val_accuracy: 0.9885 - val_loss: 6.2819e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 7.9584e-04 - val_accuracy: 1.0000 - val_loss: 3.2492e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 6.8409e-04 - val_accuracy: 1.0000 - val_loss: 9.0155e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 7.4125e-04 - val_accuracy: 1.0000 - val_loss: 6.9889e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 8.1052e-04 - val_accuracy: 1.0000 - val_loss: 5.6266e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0010 - val_accuracy: 0.9770 - val_loss: 7.1752e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 7.2678e-04 - val_accuracy: 0.9885 - val_loss: 6.1477e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 6.8445e-04 - val_accuracy: 0.9885 - val_loss: 4.8350e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 7.8185e-04 - val_accuracy: 1.0000 - val_loss: 4.8342e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 7.5693e-04 - val_accuracy: 1.0000 - val_loss: 6.1901e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 6.8541e-04 - val_accuracy: 0.9885 - val_loss: 6.1948e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 6.8791e-04 - val_accuracy: 0.9885 - val_loss: 6.7574e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 6.5692e-04 - val_accuracy: 0.9885 - val_loss: 4.6391e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 8.2576e-04 - val_accuracy: 0.9770 - val_loss: 7.3254e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 7.2332e-04 - val_accuracy: 1.0000 - val_loss: 9.0370e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 7.4702e-04 - val_accuracy: 0.9655 - val_loss: 6.9995e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 8.2767e-04 - val_accuracy: 0.9885 - val_loss: 5.2700e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 7.8130e-04 - val_accuracy: 0.9885 - val_loss: 5.6042e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 7.2094e-04 - val_accuracy: 0.9770 - val_loss: 7.0822e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 8.2865e-04 - val_accuracy: 1.0000 - val_loss: 5.1709e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 6.8695e-04 - val_accuracy: 1.0000 - val_loss: 6.7282e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 7.6217e-04 - val_accuracy: 1.0000 - val_loss: 7.7876e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 6.1268e-04 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 7.2714e-04 - val_accuracy: 0.9770 - val_loss: 8.6811e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 7.4919e-04 - val_accuracy: 0.9885 - val_loss: 5.3317e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 7.4293e-04 - val_accuracy: 0.9885 - val_loss: 9.3760e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 7.3231e-04 - val_accuracy: 1.0000 - val_loss: 4.1751e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 7.1604e-04 - val_accuracy: 0.9770 - val_loss: 6.5562e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 7.0229e-04 - val_accuracy: 0.9540 - val_loss: 6.2420e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 8.5191e-04 - val_accuracy: 0.9770 - val_loss: 6.6063e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 7.4928e-04 - val_accuracy: 1.0000 - val_loss: 9.8122e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 6.6767e-04 - val_accuracy: 0.9885 - val_loss: 6.2719e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 6.3506e-04 - val_accuracy: 0.9885 - val_loss: 0.0012\n",
      "Epoch 324/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 7.1036e-04 - val_accuracy: 0.9770 - val_loss: 6.4926e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 6.6232e-04 - val_accuracy: 1.0000 - val_loss: 8.2866e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 6.8625e-04 - val_accuracy: 0.9885 - val_loss: 6.7102e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 6.7720e-04 - val_accuracy: 0.9885 - val_loss: 6.8776e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 8.1775e-04 - val_accuracy: 0.9885 - val_loss: 5.4632e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 5.9365e-04 - val_accuracy: 0.9885 - val_loss: 4.6942e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 6.7219e-04 - val_accuracy: 1.0000 - val_loss: 7.3015e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 7.6455e-04 - val_accuracy: 0.9885 - val_loss: 5.2580e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 8.2940e-04 - val_accuracy: 1.0000 - val_loss: 4.9276e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9930 - loss: 5.5816e-04 - val_accuracy: 1.0000 - val_loss: 4.8171e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 5.7805e-04 - val_accuracy: 1.0000 - val_loss: 6.9567e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9969 - loss: 5.9225e-04 - val_accuracy: 0.9885 - val_loss: 4.5568e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9931 - loss: 5.8624e-04 - val_accuracy: 1.0000 - val_loss: 5.9691e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 6.5817e-04 - val_accuracy: 0.9885 - val_loss: 8.8879e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 6.1130e-04 - val_accuracy: 0.9885 - val_loss: 4.6951e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 5.6217e-04 - val_accuracy: 1.0000 - val_loss: 4.6193e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9938 - loss: 5.5977e-04 - val_accuracy: 0.9885 - val_loss: 4.4958e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 5.3400e-04 - val_accuracy: 0.9885 - val_loss: 4.8963e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 6.0119e-04 - val_accuracy: 0.9885 - val_loss: 6.7206e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 6.1397e-04 - val_accuracy: 0.9885 - val_loss: 3.3299e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 5.7036e-04 - val_accuracy: 1.0000 - val_loss: 6.8941e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 6.1616e-04 - val_accuracy: 0.9770 - val_loss: 4.7676e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 5.4421e-04 - val_accuracy: 0.9885 - val_loss: 0.0010\n",
      "Epoch 379/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 4.8812e-04 - val_accuracy: 0.9885 - val_loss: 9.0622e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 5.7811e-04 - val_accuracy: 1.0000 - val_loss: 4.0216e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9963 - loss: 6.6422e-04 - val_accuracy: 0.9885 - val_loss: 4.8791e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9963 - loss: 5.4983e-04 - val_accuracy: 0.9885 - val_loss: 5.7109e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9927 - loss: 5.1942e-04 - val_accuracy: 1.0000 - val_loss: 5.2900e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9933 - loss: 5.2452e-04 - val_accuracy: 1.0000 - val_loss: 5.8644e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9958 - loss: 5.6571e-04 - val_accuracy: 0.9885 - val_loss: 5.8445e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 5.7404e-04 - val_accuracy: 1.0000 - val_loss: 7.0988e-04\n",
      "Epoch 387/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 5.4666e-04 - val_accuracy: 0.9885 - val_loss: 5.0528e-04\n",
      "Epoch 388/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 5.1343e-04 - val_accuracy: 0.9885 - val_loss: 5.7529e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 5.5160e-04 - val_accuracy: 0.9885 - val_loss: 4.8362e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 5.7947e-04 - val_accuracy: 1.0000 - val_loss: 4.4065e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 6.1712e-04 - val_accuracy: 1.0000 - val_loss: 4.5391e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 5.9854e-04 - val_accuracy: 0.9770 - val_loss: 7.2638e-04\n",
      "Epoch 393/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 5.8589e-04 - val_accuracy: 1.0000 - val_loss: 3.1367e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 5.6747e-04 - val_accuracy: 1.0000 - val_loss: 7.6702e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 5.5753e-04 - val_accuracy: 0.9885 - val_loss: 6.4562e-04\n",
      "Epoch 396/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 7.0550e-04 - val_accuracy: 1.0000 - val_loss: 5.5498e-04\n",
      "Epoch 397/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 6.0812e-04 - val_accuracy: 0.9885 - val_loss: 6.0788e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 5.8843e-04 - val_accuracy: 0.9770 - val_loss: 6.0900e-04\n",
      "Epoch 399/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 5.6460e-04 - val_accuracy: 1.0000 - val_loss: 4.5114e-04\n",
      "Epoch 400/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 4.6401e-04 - val_accuracy: 1.0000 - val_loss: 5.3593e-04\n",
      "Epoch 401/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 5.7133e-04 - val_accuracy: 0.9885 - val_loss: 5.3777e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 7.3635e-04 - val_accuracy: 1.0000 - val_loss: 6.1640e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 4.9946e-04 - val_accuracy: 0.9885 - val_loss: 4.9192e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 5.4683e-04 - val_accuracy: 1.0000 - val_loss: 7.2880e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 5.2266e-04 - val_accuracy: 1.0000 - val_loss: 6.7431e-04\n",
      "Epoch 406/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 4.5345e-04 - val_accuracy: 0.9885 - val_loss: 5.3325e-04\n",
      "Epoch 407/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 5.3255e-04 - val_accuracy: 1.0000 - val_loss: 4.6317e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 5.3661e-04 - val_accuracy: 1.0000 - val_loss: 6.1219e-04\n",
      "Epoch 409/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 7.1711e-04 - val_accuracy: 0.9885 - val_loss: 4.0175e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 5.6302e-04 - val_accuracy: 1.0000 - val_loss: 4.4895e-04\n",
      "Epoch 411/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 5.5410e-04 - val_accuracy: 0.9885 - val_loss: 4.5448e-04\n",
      "Epoch 412/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 5.2280e-04 - val_accuracy: 0.9885 - val_loss: 4.2485e-04\n",
      "Epoch 413/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 5.4494e-04 - val_accuracy: 1.0000 - val_loss: 5.9643e-04\n",
      "Epoch 414/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 5.4045e-04 - val_accuracy: 1.0000 - val_loss: 5.6575e-04\n",
      "Epoch 415/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 5.2818e-04 - val_accuracy: 0.9885 - val_loss: 4.5062e-04\n",
      "Epoch 416/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 4.9531e-04 - val_accuracy: 1.0000 - val_loss: 4.4839e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 5.7422e-04 - val_accuracy: 1.0000 - val_loss: 4.6971e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 5.1630e-04 - val_accuracy: 0.9770 - val_loss: 4.3097e-04\n",
      "Epoch 419/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 5.7681e-04 - val_accuracy: 1.0000 - val_loss: 6.2080e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 6.4706e-04 - val_accuracy: 1.0000 - val_loss: 3.8380e-04\n",
      "Epoch 421/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 5.1780e-04 - val_accuracy: 0.9770 - val_loss: 7.0860e-04\n",
      "Epoch 422/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 4.5436e-04 - val_accuracy: 1.0000 - val_loss: 4.7606e-04\n",
      "Epoch 423/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 5.3271e-04 - val_accuracy: 1.0000 - val_loss: 4.6816e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 4.8219e-04 - val_accuracy: 1.0000 - val_loss: 3.8421e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 4.5994e-04 - val_accuracy: 0.9885 - val_loss: 5.1815e-04\n",
      "Epoch 503/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 4.7451e-04 - val_accuracy: 1.0000 - val_loss: 3.9825e-04\n",
      "Epoch 504/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 4.0533e-04 - val_accuracy: 1.0000 - val_loss: 3.3114e-04\n",
      "Epoch 505/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 4.1795e-04 - val_accuracy: 0.9885 - val_loss: 3.0135e-04\n",
      "Epoch 506/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 4.1241e-04 - val_accuracy: 0.9770 - val_loss: 4.9259e-04\n",
      "Epoch 507/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 3.7994e-04 - val_accuracy: 1.0000 - val_loss: 2.4972e-04\n",
      "Epoch 508/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 3.8168e-04 - val_accuracy: 0.9770 - val_loss: 4.4399e-04\n",
      "Epoch 509/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 4.1268e-04 - val_accuracy: 0.9885 - val_loss: 4.4797e-04\n",
      "Epoch 510/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 4.2264e-04 - val_accuracy: 1.0000 - val_loss: 4.1988e-04\n",
      "Epoch 511/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 4.0418e-04 - val_accuracy: 0.9885 - val_loss: 2.8626e-04\n",
      "Epoch 512/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 4.2761e-04 - val_accuracy: 0.9885 - val_loss: 5.1524e-04\n",
      "Epoch 513/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 5.3709e-04 - val_accuracy: 0.9885 - val_loss: 4.1070e-04\n",
      "Epoch 514/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 3.8829e-04 - val_accuracy: 0.9770 - val_loss: 4.6655e-04\n",
      "Epoch 515/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 4.3153e-04 - val_accuracy: 0.9885 - val_loss: 3.4449e-04\n",
      "Epoch 516/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 3.7855e-04 - val_accuracy: 0.9885 - val_loss: 2.8237e-04\n",
      "Epoch 517/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 4.0937e-04 - val_accuracy: 0.9885 - val_loss: 4.1906e-04\n",
      "Epoch 518/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 4.0384e-04 - val_accuracy: 0.9885 - val_loss: 5.3929e-04\n",
      "Epoch 519/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 4.5719e-04 - val_accuracy: 0.9885 - val_loss: 3.3896e-04\n",
      "Epoch 520/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 4.1570e-04 - val_accuracy: 1.0000 - val_loss: 3.9349e-04\n",
      "Epoch 521/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 4.1636e-04 - val_accuracy: 1.0000 - val_loss: 4.3101e-04\n",
      "Epoch 522/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 4.3991e-04 - val_accuracy: 1.0000 - val_loss: 5.7035e-04\n",
      "Epoch 523/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 4.1944e-04 - val_accuracy: 1.0000 - val_loss: 2.9599e-04\n",
      "Epoch 524/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 4.1478e-04 - val_accuracy: 0.9885 - val_loss: 4.6256e-04\n",
      "Epoch 525/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 4.2199e-04 - val_accuracy: 1.0000 - val_loss: 2.9587e-04\n",
      "Epoch 526/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 4.7101e-04 - val_accuracy: 0.9770 - val_loss: 4.1784e-04\n",
      "Epoch 527/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 4.2270e-04 - val_accuracy: 1.0000 - val_loss: 2.9521e-04\n",
      "Epoch 528/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 4.1845e-04 - val_accuracy: 0.9885 - val_loss: 4.6690e-04\n",
      "Epoch 529/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 4.5558e-04 - val_accuracy: 0.9885 - val_loss: 2.9717e-04\n",
      "Epoch 530/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 3.7303e-04 - val_accuracy: 0.9885 - val_loss: 5.0630e-04\n",
      "Epoch 531/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 4.6121e-04 - val_accuracy: 1.0000 - val_loss: 3.3174e-04\n",
      "Epoch 532/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 4.2463e-04 - val_accuracy: 0.9770 - val_loss: 2.6001e-04\n",
      "Epoch 533/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 3.9712e-04 - val_accuracy: 0.9885 - val_loss: 4.0892e-04\n",
      "Epoch 534/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9951 - loss: 3.8659e-04 - val_accuracy: 0.9885 - val_loss: 3.7450e-04\n",
      "Epoch 535/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 3.8129e-04 - val_accuracy: 1.0000 - val_loss: 3.0691e-04\n",
      "Epoch 536/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 3.8454e-04 - val_accuracy: 1.0000 - val_loss: 2.9445e-04\n",
      "Epoch 537/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 3.8155e-04 - val_accuracy: 1.0000 - val_loss: 6.8625e-04\n",
      "Epoch 538/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 3.7746e-04 - val_accuracy: 1.0000 - val_loss: 3.5530e-04\n",
      "Epoch 539/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 3.7783e-04 - val_accuracy: 0.9885 - val_loss: 3.3315e-04\n",
      "Epoch 540/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 3.6991e-04 - val_accuracy: 1.0000 - val_loss: 4.0494e-04\n",
      "Epoch 541/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 4.0602e-04 - val_accuracy: 0.9885 - val_loss: 3.2415e-04\n",
      "Epoch 542/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 3.8467e-04 - val_accuracy: 1.0000 - val_loss: 4.1848e-04\n",
      "Epoch 543/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 4.1921e-04 - val_accuracy: 0.9885 - val_loss: 4.2761e-04\n",
      "Epoch 544/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 3.6985e-04 - val_accuracy: 0.9885 - val_loss: 2.2219e-04\n",
      "Epoch 545/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 3.5405e-04 - val_accuracy: 0.9885 - val_loss: 2.3305e-04\n",
      "Epoch 546/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 3.9824e-04 - val_accuracy: 1.0000 - val_loss: 2.5259e-04\n",
      "Epoch 547/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 3.7190e-04 - val_accuracy: 0.9885 - val_loss: 3.8930e-04\n",
      "Epoch 548/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 3.8333e-04 - val_accuracy: 0.9885 - val_loss: 3.9059e-04\n",
      "Epoch 549/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 4.1800e-04 - val_accuracy: 1.0000 - val_loss: 3.2366e-04\n",
      "Epoch 550/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 4.2336e-04 - val_accuracy: 1.0000 - val_loss: 2.9384e-04\n",
      "Epoch 551/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 3.7072e-04 - val_accuracy: 0.9770 - val_loss: 3.2307e-04\n",
      "Epoch 552/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 3.6298e-04 - val_accuracy: 0.9885 - val_loss: 5.0200e-04\n",
      "Epoch 553/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 4.2473e-04 - val_accuracy: 1.0000 - val_loss: 2.8067e-04\n",
      "Epoch 554/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 3.6352e-04 - val_accuracy: 1.0000 - val_loss: 3.6674e-04\n",
      "Epoch 555/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 3.6129e-04 - val_accuracy: 1.0000 - val_loss: 2.7142e-04\n",
      "Epoch 556/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 3.7019e-04 - val_accuracy: 1.0000 - val_loss: 2.7224e-04\n",
      "Epoch 557/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 3.6107e-04 - val_accuracy: 1.0000 - val_loss: 3.2166e-04\n",
      "Epoch 558/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 3.6339e-04 - val_accuracy: 0.9770 - val_loss: 4.4845e-04\n",
      "Epoch 559/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 3.9516e-04 - val_accuracy: 1.0000 - val_loss: 2.0007e-04\n",
      "Epoch 560/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 4.0001e-04 - val_accuracy: 1.0000 - val_loss: 2.8674e-04\n",
      "Epoch 561/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 3.7071e-04 - val_accuracy: 0.9770 - val_loss: 3.7468e-04\n",
      "Epoch 562/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 4.1175e-04 - val_accuracy: 0.9885 - val_loss: 3.3121e-04\n",
      "Epoch 563/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 3.2688e-04 - val_accuracy: 0.9885 - val_loss: 3.3503e-04\n",
      "Epoch 564/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 3.6591e-04 - val_accuracy: 1.0000 - val_loss: 4.6899e-04\n",
      "Epoch 565/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 3.6898e-04 - val_accuracy: 0.9885 - val_loss: 5.0517e-04\n",
      "Epoch 566/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 3.4439e-04 - val_accuracy: 0.9885 - val_loss: 5.0138e-04\n",
      "Epoch 567/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 4.0190e-04 - val_accuracy: 1.0000 - val_loss: 3.3385e-04\n",
      "Epoch 568/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 3.8276e-04 - val_accuracy: 0.9885 - val_loss: 2.8190e-04\n",
      "Epoch 569/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 3.2637e-04 - val_accuracy: 0.9885 - val_loss: 2.7153e-04\n",
      "Epoch 570/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 3.3941e-04 - val_accuracy: 0.9885 - val_loss: 3.4941e-04\n",
      "Epoch 571/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 3.2548e-04 - val_accuracy: 0.9885 - val_loss: 3.5114e-04\n",
      "Epoch 572/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 3.5423e-04 - val_accuracy: 0.9885 - val_loss: 2.9994e-04\n",
      "Epoch 573/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 3.8089e-04 - val_accuracy: 0.9885 - val_loss: 2.7300e-04\n",
      "Epoch 574/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 3.7092e-04 - val_accuracy: 1.0000 - val_loss: 3.5273e-04\n",
      "Epoch 575/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 3.9145e-04 - val_accuracy: 0.9885 - val_loss: 2.8704e-04\n",
      "Epoch 576/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 4.0237e-04 - val_accuracy: 1.0000 - val_loss: 3.5498e-04\n",
      "Epoch 577/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9980 - loss: 3.7475e-04 - val_accuracy: 0.9885 - val_loss: 4.6416e-04\n",
      "Epoch 636/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9975 - loss: 3.5815e-04 - val_accuracy: 0.9885 - val_loss: 2.4328e-04\n",
      "Epoch 637/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9940 - loss: 3.2755e-04 - val_accuracy: 1.0000 - val_loss: 3.2902e-04\n",
      "Epoch 638/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9970 - loss: 3.2204e-04 - val_accuracy: 1.0000 - val_loss: 4.3149e-04\n",
      "Epoch 639/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9934 - loss: 3.6028e-04 - val_accuracy: 1.0000 - val_loss: 1.9349e-04\n",
      "Epoch 640/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9968 - loss: 3.1882e-04 - val_accuracy: 1.0000 - val_loss: 2.2922e-04\n",
      "Epoch 641/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 3.1943e-04 - val_accuracy: 0.9770 - val_loss: 3.0492e-04\n",
      "Epoch 642/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9955 - loss: 3.1737e-04 - val_accuracy: 1.0000 - val_loss: 2.0732e-04\n",
      "Epoch 643/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 3.1837e-04 - val_accuracy: 1.0000 - val_loss: 8.3943e-04\n",
      "Epoch 644/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 2.9374e-04 - val_accuracy: 1.0000 - val_loss: 1.9458e-04\n",
      "Epoch 645/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 3.1120e-04 - val_accuracy: 1.0000 - val_loss: 2.7006e-04\n",
      "Epoch 646/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.9745e-04 - val_accuracy: 1.0000 - val_loss: 2.8758e-04\n",
      "Epoch 647/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9967 - loss: 3.9583e-04 - val_accuracy: 1.0000 - val_loss: 3.2718e-04\n",
      "Epoch 648/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9987 - loss: 3.2887e-04 - val_accuracy: 1.0000 - val_loss: 5.9752e-04\n",
      "Epoch 649/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9934 - loss: 2.9656e-04 - val_accuracy: 1.0000 - val_loss: 2.3894e-04\n",
      "Epoch 650/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9980 - loss: 3.0766e-04 - val_accuracy: 0.9885 - val_loss: 3.3398e-04\n",
      "Epoch 651/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 3.6651e-04 - val_accuracy: 0.9885 - val_loss: 3.0440e-04\n",
      "Epoch 652/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9989 - loss: 3.1939e-04 - val_accuracy: 0.9885 - val_loss: 2.7876e-04\n",
      "Epoch 653/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9944 - loss: 3.1395e-04 - val_accuracy: 1.0000 - val_loss: 2.3943e-04\n",
      "Epoch 654/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9972 - loss: 2.9693e-04 - val_accuracy: 0.9885 - val_loss: 3.2822e-04\n",
      "Epoch 655/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 3.1896e-04 - val_accuracy: 0.9885 - val_loss: 3.6328e-04\n",
      "Epoch 656/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9963 - loss: 5.1075e-04 - val_accuracy: 0.9770 - val_loss: 3.2573e-04\n",
      "Epoch 657/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9964 - loss: 3.3634e-04 - val_accuracy: 0.9885 - val_loss: 3.0641e-04\n",
      "Epoch 658/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 3.4208e-04 - val_accuracy: 0.9770 - val_loss: 2.1471e-04\n",
      "Epoch 659/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9968 - loss: 2.8926e-04 - val_accuracy: 1.0000 - val_loss: 2.4052e-04\n",
      "Epoch 660/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 3.1506e-04 - val_accuracy: 0.9885 - val_loss: 2.8255e-04\n",
      "Epoch 661/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9980 - loss: 2.8300e-04 - val_accuracy: 0.9885 - val_loss: 2.7999e-04\n",
      "Epoch 662/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 3.2274e-04 - val_accuracy: 1.0000 - val_loss: 3.8810e-04\n",
      "Epoch 663/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 2.8411e-04 - val_accuracy: 0.9885 - val_loss: 2.9168e-04\n",
      "Epoch 664/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 3.7612e-04 - val_accuracy: 1.0000 - val_loss: 3.2317e-04\n",
      "Epoch 665/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 3.5925e-04 - val_accuracy: 1.0000 - val_loss: 3.7673e-04\n",
      "Epoch 666/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9987 - loss: 3.3254e-04 - val_accuracy: 1.0000 - val_loss: 2.4441e-04\n",
      "Epoch 667/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9936 - loss: 3.3283e-04 - val_accuracy: 0.9885 - val_loss: 4.0815e-04\n",
      "Epoch 668/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9971 - loss: 3.4300e-04 - val_accuracy: 0.9885 - val_loss: 4.5874e-04\n",
      "Epoch 669/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 3.4651e-04 - val_accuracy: 0.9885 - val_loss: 3.3445e-04\n",
      "Epoch 670/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 3.0992e-04 - val_accuracy: 0.9770 - val_loss: 3.0159e-04\n",
      "Epoch 671/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 3.4849e-04 - val_accuracy: 1.0000 - val_loss: 2.5972e-04\n",
      "Epoch 672/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 3.4200e-04 - val_accuracy: 1.0000 - val_loss: 2.7749e-04\n",
      "Epoch 673/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 3.2345e-04 - val_accuracy: 1.0000 - val_loss: 1.9776e-04\n",
      "Epoch 674/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 3.0669e-04 - val_accuracy: 1.0000 - val_loss: 2.0304e-04\n",
      "Epoch 675/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 3.2382e-04 - val_accuracy: 0.9770 - val_loss: 2.7848e-04\n",
      "Epoch 676/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 3.0848e-04 - val_accuracy: 0.9885 - val_loss: 3.1987e-04\n",
      "Epoch 677/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 3.5695e-04 - val_accuracy: 0.9885 - val_loss: 4.9381e-04\n",
      "Epoch 678/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 3.5219e-04 - val_accuracy: 1.0000 - val_loss: 2.6921e-04\n",
      "Epoch 679/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 4.1803e-04 - val_accuracy: 1.0000 - val_loss: 2.0158e-04\n",
      "Epoch 680/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 3.3268e-04 - val_accuracy: 1.0000 - val_loss: 7.3587e-04\n",
      "Epoch 681/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 3.5313e-04 - val_accuracy: 1.0000 - val_loss: 2.6954e-04\n",
      "Epoch 682/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 3.4228e-04 - val_accuracy: 0.9885 - val_loss: 2.8583e-04\n",
      "Epoch 683/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 3.0761e-04 - val_accuracy: 0.9885 - val_loss: 2.8050e-04\n",
      "Epoch 684/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 3.1306e-04 - val_accuracy: 0.9885 - val_loss: 4.8212e-04\n",
      "Epoch 685/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 3.5819e-04 - val_accuracy: 0.9885 - val_loss: 2.5594e-04\n",
      "Epoch 686/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 3.7295e-04 - val_accuracy: 0.9885 - val_loss: 2.7941e-04\n",
      "Epoch 687/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 2.9341e-04 - val_accuracy: 0.9885 - val_loss: 2.5393e-04\n",
      "Epoch 688/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 3.1536e-04 - val_accuracy: 0.9885 - val_loss: 2.6781e-04\n",
      "Epoch 689/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 3.2042e-04 - val_accuracy: 1.0000 - val_loss: 2.6733e-04\n",
      "Epoch 690/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 3.3773e-04 - val_accuracy: 1.0000 - val_loss: 2.3976e-04\n",
      "Epoch 691/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 2.9796e-04 - val_accuracy: 1.0000 - val_loss: 3.2106e-04\n",
      "Epoch 692/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 2.7476e-04 - val_accuracy: 1.0000 - val_loss: 2.8142e-04\n",
      "Epoch 693/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 3.0153e-04 - val_accuracy: 0.9885 - val_loss: 3.7178e-04\n",
      "Epoch 694/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 3.1368e-04 - val_accuracy: 0.9885 - val_loss: 2.5333e-04\n",
      "Epoch 695/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 3.0397e-04 - val_accuracy: 0.9885 - val_loss: 2.3120e-04\n",
      "Epoch 696/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 3.1623e-04 - val_accuracy: 1.0000 - val_loss: 3.0779e-04\n",
      "Epoch 697/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 2.5166e-04 - val_accuracy: 0.9885 - val_loss: 1.9895e-04\n",
      "Epoch 862/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 2.7057e-04 - val_accuracy: 1.0000 - val_loss: 2.1390e-04\n",
      "Epoch 863/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 2.4482e-04 - val_accuracy: 0.9885 - val_loss: 1.9001e-04\n",
      "Epoch 864/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 2.4495e-04 - val_accuracy: 0.9885 - val_loss: 2.6835e-04\n",
      "Epoch 865/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 2.7962e-04 - val_accuracy: 1.0000 - val_loss: 1.7040e-04\n",
      "Epoch 866/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 2.5066e-04 - val_accuracy: 0.9885 - val_loss: 3.4792e-04\n",
      "Epoch 867/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 3.6324e-04 - val_accuracy: 0.9885 - val_loss: 2.3242e-04\n",
      "Epoch 868/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 2.7345e-04 - val_accuracy: 1.0000 - val_loss: 2.9475e-04\n",
      "Epoch 869/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 2.6300e-04 - val_accuracy: 1.0000 - val_loss: 2.6841e-04\n",
      "Epoch 870/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 2.6668e-04 - val_accuracy: 1.0000 - val_loss: 2.0330e-04\n",
      "Epoch 871/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 2.6265e-04 - val_accuracy: 1.0000 - val_loss: 2.6838e-04\n",
      "Epoch 872/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 2.6181e-04 - val_accuracy: 1.0000 - val_loss: 1.5571e-04\n",
      "Epoch 873/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 2.5363e-04 - val_accuracy: 1.0000 - val_loss: 2.2385e-04\n",
      "Epoch 874/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 2.4800e-04 - val_accuracy: 1.0000 - val_loss: 1.6493e-04\n",
      "Epoch 875/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 2.5221e-04 - val_accuracy: 1.0000 - val_loss: 1.7528e-04\n",
      "Epoch 876/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 2.8144e-04 - val_accuracy: 1.0000 - val_loss: 2.9137e-04\n",
      "Epoch 877/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 2.4110e-04 - val_accuracy: 1.0000 - val_loss: 1.8438e-04\n",
      "Epoch 878/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.4164e-04 - val_accuracy: 0.9885 - val_loss: 2.5635e-04\n",
      "Epoch 879/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 2.8559e-04 - val_accuracy: 1.0000 - val_loss: 3.3507e-04\n",
      "Epoch 880/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 2.6610e-04 - val_accuracy: 0.9885 - val_loss: 2.5262e-04\n",
      "Epoch 881/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 2.6459e-04 - val_accuracy: 1.0000 - val_loss: 2.4528e-04\n",
      "Epoch 882/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 2.5824e-04 - val_accuracy: 1.0000 - val_loss: 2.9848e-04\n",
      "Epoch 883/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 3.2054e-04 - val_accuracy: 1.0000 - val_loss: 1.7469e-04\n",
      "Epoch 884/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 2.6899e-04 - val_accuracy: 0.9885 - val_loss: 2.0563e-04\n",
      "Epoch 885/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 2.5176e-04 - val_accuracy: 0.9885 - val_loss: 1.1970e-04\n",
      "Epoch 886/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 2.4889e-04 - val_accuracy: 1.0000 - val_loss: 2.4875e-04\n",
      "Epoch 887/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 2.6019e-04 - val_accuracy: 0.9885 - val_loss: 1.9151e-04\n",
      "Epoch 888/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 2.4275e-04 - val_accuracy: 0.9885 - val_loss: 2.3361e-04\n",
      "Epoch 889/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 2.5717e-04 - val_accuracy: 1.0000 - val_loss: 2.2155e-04\n",
      "Epoch 890/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 2.6842e-04 - val_accuracy: 0.9885 - val_loss: 1.8894e-04\n",
      "Epoch 891/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 2.4931e-04 - val_accuracy: 1.0000 - val_loss: 1.7683e-04\n",
      "Epoch 892/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 2.6123e-04 - val_accuracy: 1.0000 - val_loss: 2.8756e-04\n",
      "Epoch 893/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 2.4368e-04 - val_accuracy: 1.0000 - val_loss: 1.8103e-04\n",
      "Epoch 894/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 2.5140e-04 - val_accuracy: 1.0000 - val_loss: 2.4448e-04\n",
      "Epoch 895/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 2.7115e-04 - val_accuracy: 1.0000 - val_loss: 3.0724e-04\n",
      "Epoch 896/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 2.4951e-04 - val_accuracy: 0.9885 - val_loss: 2.1636e-04\n",
      "Epoch 897/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 2.6684e-04 - val_accuracy: 1.0000 - val_loss: 2.7508e-04\n",
      "Epoch 898/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 2.5605e-04 - val_accuracy: 1.0000 - val_loss: 2.2689e-04\n",
      "Epoch 899/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 2.5096e-04 - val_accuracy: 1.0000 - val_loss: 3.1221e-04\n",
      "Epoch 900/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 3.1883e-04 - val_accuracy: 1.0000 - val_loss: 2.4078e-04\n",
      "Epoch 901/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 2.5376e-04 - val_accuracy: 0.9885 - val_loss: 1.6709e-04\n",
      "Epoch 902/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 2.7237e-04 - val_accuracy: 1.0000 - val_loss: 2.5326e-04\n",
      "Epoch 903/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 2.3300e-04 - val_accuracy: 0.9885 - val_loss: 1.8067e-04\n",
      "Epoch 904/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 3.1920e-04 - val_accuracy: 1.0000 - val_loss: 1.8132e-04\n",
      "Epoch 905/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 2.4062e-04 - val_accuracy: 1.0000 - val_loss: 4.7691e-04\n",
      "Epoch 906/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 2.4925e-04 - val_accuracy: 0.9770 - val_loss: 2.7616e-04\n",
      "Epoch 907/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 2.3288e-04 - val_accuracy: 1.0000 - val_loss: 2.1359e-04\n",
      "Epoch 908/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 2.4482e-04 - val_accuracy: 1.0000 - val_loss: 2.7974e-04\n",
      "Epoch 909/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 2.7562e-04 - val_accuracy: 1.0000 - val_loss: 1.9837e-04\n",
      "Epoch 910/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 2.7900e-04 - val_accuracy: 1.0000 - val_loss: 1.8265e-04\n",
      "Epoch 911/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 2.7025e-04 - val_accuracy: 0.9885 - val_loss: 4.6715e-04\n",
      "Epoch 912/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 2.7007e-04 - val_accuracy: 1.0000 - val_loss: 2.1766e-04\n",
      "Epoch 913/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 2.5367e-04 - val_accuracy: 0.9885 - val_loss: 3.1464e-04\n",
      "Epoch 914/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 2.6931e-04 - val_accuracy: 1.0000 - val_loss: 1.7483e-04\n",
      "Epoch 915/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 2.5515e-04 - val_accuracy: 1.0000 - val_loss: 1.3889e-04\n",
      "Epoch 916/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 2.3078e-04 - val_accuracy: 1.0000 - val_loss: 1.8679e-04\n",
      "Epoch 917/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 2.7478e-04 - val_accuracy: 0.9885 - val_loss: 1.7769e-04\n",
      "Epoch 918/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 2.3117e-04 - val_accuracy: 1.0000 - val_loss: 2.4359e-04\n",
      "Epoch 919/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 2.6666e-04 - val_accuracy: 1.0000 - val_loss: 1.5932e-04\n",
      "Epoch 920/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 2.7490e-04 - val_accuracy: 1.0000 - val_loss: 2.0150e-04\n",
      "Epoch 921/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 2.3457e-04 - val_accuracy: 1.0000 - val_loss: 2.6457e-04\n",
      "Epoch 922/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 2.6420e-04 - val_accuracy: 1.0000 - val_loss: 1.9204e-04\n",
      "Epoch 923/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 2.5047e-04 - val_accuracy: 0.9885 - val_loss: 3.7795e-04\n",
      "Epoch 924/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 2.5940e-04 - val_accuracy: 1.0000 - val_loss: 2.2296e-04\n",
      "Epoch 925/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 2.3812e-04 - val_accuracy: 0.9885 - val_loss: 2.9513e-04\n",
      "Epoch 926/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 2.3621e-04 - val_accuracy: 1.0000 - val_loss: 1.3038e-04\n",
      "Epoch 927/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 2.5235e-04 - val_accuracy: 0.9885 - val_loss: 2.2371e-04\n",
      "Epoch 928/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 2.7713e-04 - val_accuracy: 1.0000 - val_loss: 3.2415e-04\n",
      "Epoch 929/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 2.3577e-04 - val_accuracy: 1.0000 - val_loss: 1.7511e-04\n",
      "Epoch 930/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 2.4918e-04 - val_accuracy: 0.9885 - val_loss: 2.2382e-04\n",
      "Epoch 931/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 2.3105e-04 - val_accuracy: 1.0000 - val_loss: 2.0021e-04\n",
      "Epoch 932/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 2.4199e-04 - val_accuracy: 0.9885 - val_loss: 1.7133e-04\n",
      "Epoch 933/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 2.2547e-04 - val_accuracy: 1.0000 - val_loss: 1.5678e-04\n",
      "Epoch 934/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 2.4155e-04 - val_accuracy: 1.0000 - val_loss: 2.2886e-04\n",
      "Epoch 935/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 2.5925e-04 - val_accuracy: 1.0000 - val_loss: 2.2650e-04\n",
      "Epoch 936/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 2.3974e-04 - val_accuracy: 1.0000 - val_loss: 1.5924e-04\n",
      "Epoch 937/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3234e-04 - val_accuracy: 1.0000 - val_loss: 1.2681e-04\n",
      "Epoch 938/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 2.3873e-04 - val_accuracy: 0.9885 - val_loss: 1.3832e-04\n",
      "Epoch 939/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 2.5204e-04 - val_accuracy: 1.0000 - val_loss: 3.6994e-04\n",
      "Epoch 940/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 2.4430e-04 - val_accuracy: 0.9885 - val_loss: 3.0494e-04\n",
      "Epoch 941/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 2.3338e-04 - val_accuracy: 0.9885 - val_loss: 1.8984e-04\n",
      "Epoch 942/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 2.4233e-04 - val_accuracy: 1.0000 - val_loss: 1.2656e-04\n",
      "Epoch 943/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 2.3620e-04 - val_accuracy: 0.9885 - val_loss: 2.0227e-04\n",
      "Epoch 944/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 2.6429e-04 - val_accuracy: 1.0000 - val_loss: 1.7693e-04\n",
      "Epoch 945/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 2.4659e-04 - val_accuracy: 1.0000 - val_loss: 2.2574e-04\n",
      "Epoch 946/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 2.5458e-04 - val_accuracy: 0.9885 - val_loss: 1.9026e-04\n",
      "Epoch 947/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 2.6983e-04 - val_accuracy: 1.0000 - val_loss: 1.6564e-04\n",
      "Epoch 948/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 2.3955e-04 - val_accuracy: 1.0000 - val_loss: 2.0609e-04\n",
      "Epoch 949/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 2.3433e-04 - val_accuracy: 0.9885 - val_loss: 1.5613e-04\n",
      "Epoch 950/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 2.3753e-04 - val_accuracy: 1.0000 - val_loss: 1.9054e-04\n",
      "Epoch 951/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 2.5153e-04 - val_accuracy: 1.0000 - val_loss: 2.4370e-04\n",
      "Epoch 952/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 2.3525e-04 - val_accuracy: 1.0000 - val_loss: 2.0455e-04\n",
      "Epoch 953/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 2.4615e-04 - val_accuracy: 0.9885 - val_loss: 2.0430e-04\n",
      "Epoch 954/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 2.7382e-04 - val_accuracy: 0.9885 - val_loss: 2.8336e-04\n",
      "Epoch 955/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 2.6270e-04 - val_accuracy: 1.0000 - val_loss: 1.9293e-04\n",
      "Epoch 956/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 2.4996e-04 - val_accuracy: 1.0000 - val_loss: 1.8294e-04\n",
      "Epoch 957/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 2.6863e-04 - val_accuracy: 1.0000 - val_loss: 2.6731e-04\n",
      "Epoch 958/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 2.2186e-04 - val_accuracy: 1.0000 - val_loss: 2.1049e-04\n",
      "Epoch 959/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 2.1235e-04 - val_accuracy: 1.0000 - val_loss: 1.8158e-04\n",
      "Epoch 960/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 2.4530e-04 - val_accuracy: 1.0000 - val_loss: 1.7778e-04\n",
      "Epoch 961/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 2.4120e-04 - val_accuracy: 1.0000 - val_loss: 1.6048e-04\n",
      "Epoch 962/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 2.2335e-04 - val_accuracy: 1.0000 - val_loss: 2.0957e-04\n",
      "Epoch 963/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 2.4349e-04 - val_accuracy: 1.0000 - val_loss: 1.5742e-04\n",
      "Epoch 964/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 2.3779e-04 - val_accuracy: 1.0000 - val_loss: 3.3934e-04\n",
      "Epoch 965/1000\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 2.6537e-04 - val_accuracy: 1.0000 - val_loss: 1.9454e-04\n",
      "Epoch 966/1000\n",
      "\u001b[1m 69/218\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 2.1246e-04"
     ]
    }
   ],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 1000\n",
    "Shift_Range = 3\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Learing results (Step 1 & Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(val_loss_ges)\n",
    "\n",
    "\n",
    "plt.semilogy(loss_ges)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* The evaluation takes the periodic character of the results into account (dev1 ... dev2).\n",
    "* Images, that have a bigger deviation as the parameter \"deviation_max_list\" are printed in a list to check the picture and labeling itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='data_resize_all'\n",
    "#Input_dir='test_result'\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "res = []\n",
    "stat_Anz = []\n",
    "stat_Abweichung = []\n",
    "i = 0\n",
    "deviation_max_list = 0.15\n",
    "\n",
    "for i in range(100):\n",
    "    stat_Anz.append(0)\n",
    "    stat_Abweichung.append(0)\n",
    "\n",
    "for aktfile in sorted(files):\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = (float(base[0:3])) / 10\n",
    "    \n",
    "    target_sin = math.sin(target * math.pi * 2)\n",
    "    target_cos = math.cos(target * math.pi * 2)\n",
    "\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,32,3])\n",
    "    classes = model.predict(img, verbose=0)\n",
    "    \n",
    "    out_sin = classes[0][0]  \n",
    "    out_cos = classes[0][1]\n",
    "    out_target = (np.arctan2(out_sin, out_cos)/(2*math.pi)) % 1\n",
    "\n",
    "    dev_sin = target_sin - out_sin\n",
    "    dev_cos = target_cos - out_cos\n",
    "    dev_target = target - out_target\n",
    "    \n",
    "    if abs(dev_target + 1) < abs(dev_target):\n",
    "        out_target = out_target - 1\n",
    "        dev_target = target - out_target\n",
    "    else:\n",
    "        if abs(dev_target - 1) < abs(dev_target):\n",
    "            out_target = out_target + 1\n",
    "            dev_target = target - out_target\n",
    "            \n",
    "    target_int = int ((float(base[0:3])) * 10)\n",
    "    stat_Abweichung[target_int] = stat_Abweichung[target_int] + dev_target  \n",
    "    stat_Anz[target_int] = stat_Anz[target_int] + 1\n",
    "               \n",
    "    res.append(np.array([target, out_target, dev_target, out_sin, out_cos, i]))\n",
    "    if abs(dev_target) > deviation_max_list:\n",
    "        print(aktfile + \" \" + str(target) + \" \" + str(out_target) +  \" \" + str(dev_target))\n",
    "\n",
    "    \n",
    "for i in range(100):\n",
    "    stat_Abweichung[i] = stat_Abweichung[i] / stat_Anz[i]\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,3])\n",
    "plt.plot(res[:,4])\n",
    "plt.title('Result')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['sin', 'cos'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stat_Abweichung)\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stat_Anz)\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation from Expected Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,2])\n",
    "plt.title('Deviation')\n",
    "plt.ylabel('Deviation from expected value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Deviation'], loc='upper left')\n",
    "#plt.ylim(-0.3, 0.3)\n",
    "plt.show()\n",
    "\n",
    "statistic = np.array([np.mean(res[:,2]), np.std(res[:,2]), np.min(res[:,2]), np.max(res[:,2])])\n",
    "print(statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(\"test\", \"tf_saved_model\")  # replace tf.saved_model.save with this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFlite_MainType + \"_\" + TFlite_Version + \"_\" + TFlite_Size\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"test\")\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "FileName = FileName = TFlite_MainType + \"_\" + TFlite_Version + \"_\" + TFlite_Size + \"_q.tflite\"\n",
    "\n",
    "def representative_dataset():\n",
    "    for n in range(x_data[0].size):\n",
    "      data = np.expand_dims(x_data[5], axis=0)\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"test\")\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName, \"wb\").write(tflite_quant_model)\n",
    "print(FileName)\n",
    "Path(FileName).stat().st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3431513051aa6ef6a02e4978d18932220794b1f41fa21fbae2ad068757488314"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
