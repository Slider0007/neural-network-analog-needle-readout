{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to extract the needle position of an analog needle device.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFlite_Version  = \"1209\"   \n",
    "TFlite_MainType = \"ana-cont\"\n",
    "TFlite_Size     = \"s2\"\n",
    "Training_Percentage = 0.2              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 100\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History \n",
    "import math\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Picture size must be 32x32 with 3 color channels (RGB)\n",
    "* The filename contains the informations needed for training in the first 3 digits::\n",
    "* Typical filename: \n",
    "    * x.y-zzzz.jpg \n",
    "    * e.g. \"4.6_Lfd-1406_zeiger3_2019-06-02T050011\"\n",
    "\n",
    "|Place holder | Meaning                     | Usage        |\n",
    "|------------- |-----------------------------|--------------|\n",
    "| **x.y**          | readout value               | **to be learned** |\n",
    "| zzzz        | additional information              | not needed   |\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected output for each image in the corresponding y_data[]\n",
    "    * The periodic nature is reflected in a **sin/cos coding**, which allows to restore the angle/counter value with an arctan later on.\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) as the filenames are on order due to the encoding of the expected analog readout in the filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='data_resize_all'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    test_image = np.reshape(test_image, (32,32,3))\n",
    "    base = os.path.basename(aktfile)\n",
    "    target_number = (float(base[0:3])) / 10\n",
    "    target_sin = math.sin(target_number * math.pi * 2)\n",
    "    target_cos = math.cos(target_number * math.pi * 2)\n",
    "\n",
    "    x_data.append(test_image)\n",
    "    zw = np.array([target_sin, target_cos])\n",
    "    y_data.append(zw)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 32, 3)\n",
    "* Shape of the output layer: (2) - sin and cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "inputs2 = tf.keras.layers.BatchNormalization()(inputs)\n",
    "inputs3 = tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation=\"relu\")(inputs2)\n",
    "inputs4 = tf.keras.layers.MaxPool2D(pool_size=(4,4))(inputs3)\n",
    "inputs5 = tf.keras.layers.Conv2D(16, (5, 5), padding='same', activation=\"relu\")(inputs4)\n",
    "inputs6 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs5)\n",
    "inputs7 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\")(inputs6)\n",
    "inputs8 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(inputs7)\n",
    "inputs9 = tf.keras.layers.Flatten()(inputs8)\n",
    "inputs10 = tf.keras.layers.Dense(128,activation=\"relu\")(inputs9)\n",
    "inputs11 = tf.keras.layers.Dense(64,activation=\"relu\")(inputs10)\n",
    "output = tf.keras.layers.Dense(2)(inputs11)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(loss=keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness and pixel shift variations. These is implemented with a ImageDataGenerator.\n",
    "\n",
    "\n",
    "The training is splitted into two steps:\n",
    "1. Variation of the brightness only\n",
    "2. Variation of brightness and Pixel Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Brigthness scattering only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 30\n",
    "Shift_Range = 0\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(val_loss_ges)\n",
    "\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Brigthness and Pixel Shift scattering\n",
    "Here a higher number of epochs is used to reach the minimum loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 160\n",
    "Shift_Range = 3\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, epochs = Epoch_Anz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Learing results (Step 1 & Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(val_loss_ges)\n",
    "\n",
    "\n",
    "plt.semilogy(loss_ges)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* The evaluation takes the periodic character of the results into account (dev1 ... dev2).\n",
    "* Images, that have a bigger deviation as the parameter \"deviation_max_list\" are printed in a list to check the picture and labeling itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_resize_all\\6.2_name_20230216-151847.jpg 0.62 0.7678980863626853 -0.1478980863626853\n",
      "data_resize_all\\6.2_name_20230216-221846.jpg 0.62 0.8457273709905683 -0.22572737099056828\n",
      "data_resize_all\\6.3_name_20230216-010348.jpg 0.63 0.89044907808235 -0.26044907808234996\n",
      "data_resize_all\\6.3_name_20230216-183346.jpg 0.63 0.8935064415095769 -0.2635064415095769\n",
      "data_resize_all\\6.4_PRODUCED_ANALOG_2.jpg 0.64 0.7153626238876614 -0.07536262388766135\n",
      "data_resize_all\\6.4_name_20230216-072347.jpg 0.64 0.8048181806297492 -0.16481818062974918\n",
      "data_resize_all\\6.4_name_20230216-124347.jpg 0.64 0.8292484202257985 -0.18924842022579846\n",
      "data_resize_all\\6.4_name_20230216-152847.jpg 0.64 0.7098311951883265 -0.06983119518832648\n",
      "data_resize_all\\6.5_name_20230216-010848.jpg 0.65 0.8252278673163659 -0.17522786731636586\n",
      "data_resize_all\\6.5_name_20230216-011348.jpg 0.65 0.7648456748226067 -0.11484567482260666\n",
      "data_resize_all\\6.5_name_20230216-012348.jpg 0.65 0.8000622250469309 -0.1500622250469309\n",
      "data_resize_all\\6.5_name_20230216-112847.jpg 0.65 0.8056397954686587 -0.1556397954686587\n",
      "data_resize_all\\6.5_name_20230216-124847.jpg 0.65 0.9239964154508876 -0.2739964154508876\n",
      "data_resize_all\\6.5_name_20230216-194346.jpg 0.65 0.7047935322477406 -0.05479353224774053\n",
      "data_resize_all\\6.6_3396_zeiger1_2020-04-29_13-09-02.jpg 0.6599999999999999 0.714285465110055 -0.05428546511005505\n",
      "data_resize_all\\6.6_name_20230216-012848.jpg 0.6599999999999999 0.7837356444188954 -0.12373564441889551\n",
      "data_resize_all\\6.6_name_20230216-013348.jpg 0.6599999999999999 0.9492816050035456 -0.2892816050035457\n",
      "data_resize_all\\6.6_name_20230216-072847.jpg 0.6599999999999999 0.9523935150803942 -0.29239351508039424\n",
      "data_resize_all\\6.6_name_20230216-205846.jpg 0.6599999999999999 0.8356607915460834 -0.1756607915460835\n",
      "data_resize_all\\6.6_name_20230216-222346.jpg 0.6599999999999999 0.8870106849631747 -0.22701068496317478\n",
      "data_resize_all\\6.7_PRODUCED_ANALOG_2.jpg 0.67 0.7236576989071649 -0.053657698907164875\n",
      "data_resize_all\\6.7_name_20230216-013848.jpg 0.67 0.9802864257978873 -0.31028642579788723\n",
      "data_resize_all\\6.7_name_20230216-142347.jpg 0.67 0.7978581988927586 -0.1278581988927585\n",
      "data_resize_all\\6.8_name_20230216-014348.jpg 0.6799999999999999 0.8432559239576423 -0.16325592395764232\n",
      "data_resize_all\\6.8_name_20230216-153847.jpg 0.6799999999999999 0.8536433041065191 -0.17364330410651918\n",
      "data_resize_all\\6.8_name_20230216-183846.jpg 0.6799999999999999 0.8661821179529593 -0.18618211795295936\n",
      "data_resize_all\\6.9_name_20230216-085847.jpg 0.6900000000000001 0.7765839430664521 -0.08658394306645201\n",
      "data_resize_all\\6.9_name_20230216-184346.jpg 0.6900000000000001 0.8304504007104869 -0.14045040071048687\n",
      "data_resize_all\\6.9_name_20230216-210346.jpg 0.6900000000000001 0.7746224834915536 -0.08462248349155355\n",
      "data_resize_all\\6.9_name_20230216-235346.jpg 0.6900000000000001 0.8676340549021486 -0.17763405490214856\n",
      "data_resize_all\\7.0_name_20230216-014848.jpg 0.7 0.7581061564138258 -0.05810615641382588\n",
      "data_resize_all\\7.0_name_20230216-015348.jpg 0.7 0.8566481699408754 -0.1566481699408755\n",
      "data_resize_all\\7.0_name_20230216-073347.jpg 0.7 0.8549462480680637 -0.15494624806806379\n",
      "data_resize_all\\7.0_name_20230216-113347.jpg 0.7 0.8592928950784952 -0.1592928950784952\n",
      "data_resize_all\\7.1_PRODUCED_ANALOG_2.jpg 0.71 1.148510311457029 -0.438510311457029\n",
      "data_resize_all\\7.1_name_20230216-015848.jpg 0.71 0.8180780063204489 -0.10807800632044895\n",
      "data_resize_all\\7.1_name_20230216-020348.jpg 0.71 0.8959115123846938 -0.18591151238469383\n",
      "data_resize_all\\7.2_name_20230216-154347.jpg 0.72 0.7865398355008872 -0.06653983550088727\n",
      "data_resize_all\\7.2_name_20230216-184846.jpg 0.72 0.7884350991590796 -0.06843509915907964\n",
      "data_resize_all\\7.2_name_20230216-222846.jpg 0.72 0.7974734695150099 -0.07747346951500989\n",
      "data_resize_all\\7.3_main_ana3_20221213-141633.jpg 0.73 0.28747218920910933 0.44252781079089065\n",
      "data_resize_all\\7.3_name_20230216-023848.jpg 0.73 0.7875381055935801 -0.05753810559358008\n",
      "data_resize_all\\7.3_name_20230216-024348.jpg 0.73 0.8683817044841712 -0.1383817044841712\n",
      "data_resize_all\\7.3_name_20230216-025348.jpg 0.73 0.8405564055246808 -0.11055640552468082\n",
      "data_resize_all\\7.3_name_20230216-030348.jpg 0.73 0.7815066311560095 -0.05150663115600951\n",
      "data_resize_all\\7.3_name_20230216-125347.jpg 0.73 0.9246529436689205 -0.1946529436689205\n",
      "data_resize_all\\7.3_name_20230216-154847.jpg 0.73 0.8165313289556472 -0.08653132895564719\n",
      "data_resize_all\\7.3_name_20230216-235846.jpg 0.73 0.8410754240106111 -0.1110754240106111\n",
      "data_resize_all\\7.4_name_20230216-074847.jpg 0.74 0.8340612940517003 -0.09406129405170027\n",
      "data_resize_all\\7.4_name_20230216-104847.jpg 0.74 0.8224132981413852 -0.0824132981413852\n",
      "data_resize_all\\7.4_name_20230216-155347.jpg 0.74 0.8450782753464448 -0.10507827534644476\n",
      "data_resize_all\\7.5_name_20230216-030848.jpg 0.75 0.828338506219119 -0.07833850621911898\n",
      "data_resize_all\\7.5_name_20230216-031348.jpg 0.75 0.848657569576373 -0.09865756957637295\n",
      "data_resize_all\\7.5_name_20230216-155847.jpg 0.75 0.8470447816722299 -0.09704478167222985\n",
      "data_resize_all\\7.5_name_20230216-185846.jpg 0.75 0.879226081206765 -0.12922608120676504\n",
      "data_resize_all\\7.6_name_20230216-090347.jpg 0.76 0.8732610398452467 -0.11326103984524671\n",
      "data_resize_all\\7.6_name_20230216-160347.jpg 0.76 0.8324306812510982 -0.0724306812510982\n",
      "data_resize_all\\7.6_name_20230216-160847.jpg 0.76 0.8144123766021368 -0.054412376602136825\n",
      "data_resize_all\\7.7_name_20230216-031848.jpg 0.77 0.8273196317224301 -0.05731963172243004\n",
      "data_resize_all\\7.7_name_20230216-142847.jpg 0.77 0.8428154336744195 -0.07281543367441945\n",
      "data_resize_all\\7.8_8fba333844b371359879dcb0df4c04da.jpg 0.78 0.6074009541806393 0.1725990458193607\n",
      "data_resize_all\\7.8_name_20230216-090847.jpg 0.78 0.8359734624280885 -0.05597346242808843\n",
      "data_resize_all\\7.8_name_20230216-161346.jpg 0.78 0.8526241545049886 -0.0726241545049886\n",
      "data_resize_all\\7.8_name_20230216-170846.jpg 0.78 0.8786337235646218 -0.09863372356462174\n",
      "data_resize_all\\7.9_4fc59d4990b9ab81712f18c24f52f6e9.jpg 0.79 1.023520214124477 -0.233520214124477\n",
      "data_resize_all\\7.9_name_20230216-034347.jpg 0.79 0.841699096172824 -0.05169909617282398\n",
      "data_resize_all\\7.9_name_20230216-034847.jpg 0.79 0.8460308306035675 -0.056030830603567505\n",
      "data_resize_all\\7.9_name_20230216-162846.jpg 0.79 0.8655488740395345 -0.07554887403953447\n",
      "data_resize_all\\7.9_name_20230216-163346.jpg 0.79 0.8412919410073004 -0.05129194100730039\n",
      "data_resize_all\\7.9_name_20230216-223846.jpg 0.79 0.856896845744907 -0.06689684574490695\n",
      "data_resize_all\\8.0_name_20230216-040847.jpg 0.8 0.8536185067252825 -0.053618506725282455\n",
      "data_resize_all\\8.0_name_20230216-113847.jpg 0.8 0.8603499427435455 -0.06034994274354544\n",
      "data_resize_all\\8.1_831681272346101c1cf606c92f7c0378.jpg 0.8099999999999999 0.8817502724782817 -0.0717502724782818\n",
      "data_resize_all\\8.1_PRODUCED_ANALOG_2.jpg 0.8099999999999999 1.1674464322620846 -0.3574464322620846\n",
      "data_resize_all\\8.2_4086_zeiger3_2019-06-04T192009.jpg 0.82 0.9298818234471453 -0.10988182344714537\n",
      "data_resize_all\\8.2_4087_zeiger3_2019-06-04T193009.jpg 0.82 0.8926409047597548 -0.07264090475975482\n",
      "data_resize_all\\8.2_4090_zeiger3_2019-06-05T185008.jpg 0.82 0.8812356177243212 -0.06123561772432129\n",
      "data_resize_all\\8.2_4091_zeiger3_2019-06-05T190009.jpg 0.82 0.8796377898317352 -0.05963778983173529\n",
      "data_resize_all\\8.2_ana3_20220629-165729.jpg 0.82 0.7681331587066199 0.05186684129338004\n",
      "data_resize_all\\8.3_4089_zeiger3_2019-06-05T181009.jpg 0.8300000000000001 0.9998265658333397 -0.16982656583333966\n",
      "data_resize_all\\8.3_4123_zeiger3_2019-06-04T104010.jpg 0.8300000000000001 0.8862393004737864 -0.056239300473786336\n",
      "data_resize_all\\8.3_4124_zeiger3_2019-06-05T043009.jpg 0.8300000000000001 1.021007062620525 -0.19100706262052491\n",
      "data_resize_all\\8.3_4125_zeiger3_2019-06-05T180009.jpg 0.8300000000000001 0.9960542640459563 -0.16605426404595625\n",
      "data_resize_all\\8.3_4126_zeiger3_2019-06-05T182008.jpg 0.8300000000000001 0.9919877268286468 -0.1619877268286467\n",
      "data_resize_all\\8.3_4134_zeiger4_2019-06-05T045009.jpg 0.8300000000000001 0.8834730359144358 -0.05347303591443575\n",
      "data_resize_all\\8.3_4147_zeiger3_2019-06-01T185013.jpg 0.8300000000000001 0.9613125349953587 -0.13131253499535867\n",
      "data_resize_all\\8.3_4148_zeiger3_2019-06-01T190020.jpg 0.8300000000000001 0.9805638666590171 -0.150563866659017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_resize_all\\8.3_4149_zeiger3_2019-06-01T191021.jpg 0.8300000000000001 0.9630993195970146 -0.1330993195970145\n",
      "data_resize_all\\8.3_4150_zeiger3_2019-06-01T192013.jpg 0.8300000000000001 0.8994771082907866 -0.06947710829078657\n",
      "data_resize_all\\8.3_4151_zeiger3_2019-06-01T193014.jpg 0.8300000000000001 0.9595139967765063 -0.1295139967765062\n",
      "data_resize_all\\8.3_4152_zeiger3_2019-06-01T194012.jpg 0.8300000000000001 0.9636462635959575 -0.13364626359595744\n",
      "data_resize_all\\8.3_4153_zeiger3_2019-06-01T195015.jpg 0.8300000000000001 0.963907489872589 -0.13390748987258894\n",
      "data_resize_all\\8.3_4154_zeiger3_2019-06-01T200012.jpg 0.8300000000000001 0.9324056257773343 -0.10240562577733425\n",
      "data_resize_all\\8.3_4155_zeiger3_2019-06-01T204131.jpg 0.8300000000000001 0.9487901539200155 -0.11879015392001546\n",
      "data_resize_all\\8.3_PRODUCED_ANALOG_2.jpg 0.8300000000000001 0.9767361693583054 -0.14673616935830536\n",
      "data_resize_all\\8.3_name_20230216-202346.jpg 0.8300000000000001 0.8997911452106256 -0.06979114521062557\n",
      "data_resize_all\\8.4_53b64949db739b0efc878875cca0fabf.jpg 0.8400000000000001 0.7896050536456598 0.050394946354340275\n",
      "data_resize_all\\8.5_689bdb99de46477b76a2410771ca3430.jpg 0.85 0.9358395508144274 -0.0858395508144274\n",
      "data_resize_all\\8.6_name_20230216-130847.jpg 0.86 0.9179730992948257 -0.05797309929482575\n",
      "data_resize_all\\8.8_pointer_20211018-091349.jpg 0.8800000000000001 0.9302209186235019 -0.050220918623501754\n",
      "data_resize_all\\8.8_pointer_20211018-120349.jpg 0.8800000000000001 0.9361034143029884 -0.056103414302988264\n",
      "data_resize_all\\9.0_4474_zeiger3_2020-02-12_16-41-06.jpg 0.9 0.9859282189705608 -0.0859282189705608\n",
      "data_resize_all\\9.1_analog2_20200928-062801.jpg 0.9099999999999999 1.1576248953404478 -0.24762489534044785\n",
      "data_resize_all\\9.2_4568_zeiger4_2020-04-29_11-21-01.jpg 0.9199999999999999 1.083591640125781 -0.1635916401257811\n",
      "data_resize_all\\9.2_4570_zeiger4_2020-04-29_12-26-02.jpg 0.9199999999999999 1.095346035205167 -0.175346035205167\n",
      "data_resize_all\\9.2_4571_zeiger4_2020-04-29_12-45-02.jpg 0.9199999999999999 0.9846576496313635 -0.06465764963136356\n",
      "data_resize_all\\9.2_4584_zeiger2_2019-09-14_19-20-12.jpg 0.9199999999999999 1.1543207533839588 -0.23432075338395886\n",
      "data_resize_all\\9.2_4585_zeiger2_2019-09-14_19-30-13.jpg 0.9199999999999999 1.10494635937506 -0.18494635937506\n",
      "data_resize_all\\9.3_4613_zeiger4_2020-04-29_13-18-02.jpg 0.93 1.0545156149495885 -0.1245156149495884\n",
      "data_resize_all\\9.3_4614_zeiger4_2020-04-29_14-29-02.jpg 0.93 1.1039327782749777 -0.17393277827497766\n",
      "data_resize_all\\9.3_analog2_20201003-152354.jpg 0.93 0.9932594588415388 -0.06325945884153872\n",
      "data_resize_all\\9.4_4729_zeiger4_2020-04-29_10-47-26.jpg 0.9400000000000001 0.9994840934523094 -0.05948409345230932\n",
      "data_resize_all\\9.4_analog3_20200928-061428.jpg 0.9400000000000001 0.9908212568057604 -0.05082125680576033\n",
      "data_resize_all\\9.4_bdeab982fbac878494bf669d45b91020.jpg 0.9400000000000001 1.1184175130159544 -0.17841751301595432\n",
      "data_resize_all\\9.5_4784_zeiger4_2020-04-29_13-10-02.jpg 0.95 1.017315354860507 -0.06731535486050699\n",
      "data_resize_all\\9.7_4796_zeiger2_2020-04-29_12-46-02.jpg 0.97 1.0441715827860063 -0.07417158278600633\n",
      "data_resize_all\\9.7_4802_zeiger4_2020-04-29_11-34-02.jpg 0.97 1.049811454967976 -0.07981145496797604\n",
      "data_resize_all\\9.7_4803_zeiger4_2020-04-29_11-55-02.jpg 0.97 1.0507455260256575 -0.08074552602565754\n",
      "data_resize_all\\9.7_4805_zeiger4_2020-04-29_13-58-01.jpg 0.97 1.0720107413376876 -0.10201074133768762\n",
      "data_resize_all\\9.7_4854_zeiger4_2020-04-29_12-38-01.jpg 0.97 1.0635863575562723 -0.09358635755627231\n",
      "data_resize_all\\9.9_name_20230216-132347.jpg 0.99 0.9284985298991146 0.06150147010088536\n"
     ]
    }
   ],
   "source": [
    "Input_dir='data_resize_all'\n",
    "#Input_dir='test_result'\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "res = []\n",
    "stat_Anz = []\n",
    "stat_Abweichung = []\n",
    "i = 0\n",
    "deviation_max_list = 0.05\n",
    "\n",
    "for i in range(100):\n",
    "    stat_Anz.append(0)\n",
    "    stat_Abweichung.append(0)\n",
    "\n",
    "for aktfile in sorted(files):\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = (float(base[0:3])) / 10\n",
    "    \n",
    "    target_sin = math.sin(target * math.pi * 2)\n",
    "    target_cos = math.cos(target * math.pi * 2)\n",
    "\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,32,3])\n",
    "    classes = model.predict(img, verbose=0)\n",
    "    \n",
    "    out_sin = classes[0][0]  \n",
    "    out_cos = classes[0][1]\n",
    "    out_target = (np.arctan2(out_sin, out_cos)/(2*math.pi)) % 1\n",
    "\n",
    "    dev_sin = target_sin - out_sin\n",
    "    dev_cos = target_cos - out_cos\n",
    "    dev_target = target - out_target\n",
    "    \n",
    "    if abs(dev_target + 1) < abs(dev_target):\n",
    "        out_target = out_target - 1\n",
    "        dev_target = target - out_target\n",
    "    else:\n",
    "        if abs(dev_target - 1) < abs(dev_target):\n",
    "            out_target = out_target + 1\n",
    "            dev_target = target - out_target\n",
    "            \n",
    "    target_int = int ((float(base[0:3])) * 10)\n",
    "    stat_Abweichung[target_int] = stat_Abweichung[target_int] + dev_target  \n",
    "    stat_Anz[target_int] = stat_Anz[target_int] + 1\n",
    "               \n",
    "    res.append(np.array([target, out_target, dev_target, out_sin, out_cos, i]))\n",
    "    if abs(dev_target) > deviation_max_list:\n",
    "        print(aktfile + \" \" + str(target) + \" \" + str(out_target) +  \" \" + str(dev_target))\n",
    "\n",
    "    \n",
    "for i in range(100):\n",
    "    stat_Abweichung[i] = stat_Abweichung[i] / stat_Anz[i]\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,3])\n",
    "plt.plot(res[:,4])\n",
    "plt.title('Result')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['sin', 'cos'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stat_Abweichung)\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stat_Anz)\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation from Expected Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,2])\n",
    "plt.title('Deviation')\n",
    "plt.ylabel('Deviation from expected value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Deviation'], loc='upper left')\n",
    "#plt.ylim(-0.3, 0.3)\n",
    "plt.show()\n",
    "\n",
    "statistic = np.array([np.mean(res[:,2]), np.std(res[:,2]), np.min(res[:,2]), np.max(res[:,2])])\n",
    "print(statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFlite_MainType + \"_\" + TFlite_Version + \"_\" + TFlite_Size\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "FileName = FileName = TFlite_MainType + \"_\" + TFlite_Version + \"_\" + TFlite_Size + \"_q.tflite\"\n",
    "\n",
    "def representative_dataset():\n",
    "    for n in range(x_data[0].size):\n",
    "      data = np.expand_dims(x_data[n], axis=0)\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName, \"wb\").write(tflite_quant_model)\n",
    "print(FileName)\n",
    "Path(FileName).stat().st_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3431513051aa6ef6a02e4978d18932220794b1f41fa21fbae2ad068757488314"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
