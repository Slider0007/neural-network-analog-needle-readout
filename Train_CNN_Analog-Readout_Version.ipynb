{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to extract the needle position of an analog needle device.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History \n",
    "import math\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Picture size must be 32x32 with 3 color channels (RGB)\n",
    "* The filename contains the informations needed for training in the first 3 digits::\n",
    "* Typical filename: \n",
    "    * x.y-zzzz.jpg \n",
    "    * e.g. \"4.6_Lfd-1406_zeiger3_2019-06-02T050011\"\n",
    "\n",
    "|Place holder | Meaning                     | Usage        |\n",
    "|------------- |-----------------------------|--------------|\n",
    "| **x.y**          | readout value               | **to be learned** |\n",
    "| zzzz        | additional information              | not needed   |\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected output for each image in the corresponding y_data[]\n",
    "    * The periodic nature is reflected in a **sin/cos coding**, which allows to restore the angle/counter value with an arctan later on.\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) as the filenames are on order due to the encoding of the expected analog readout in the filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3855, 32, 32, 3)\n",
      "(3855, 2)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='data_resize_all'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    test_image = np.reshape(test_image, (32,32,3))\n",
    "    base = os.path.basename(aktfile)\n",
    "    target_number = (float(base[0:3])) / 10\n",
    "    target_sin = math.sin(target_number * math.pi * 2)\n",
    "    target_cos = math.cos(target_number * math.pi * 2)\n",
    "\n",
    "    x_data.append(test_image)\n",
    "    zw = np.array([target_sin, target_cos])\n",
    "    y_data.append(zw)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 32, 3)\n",
    "* Shape of the output layer: (2) - sin and cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 32)          51232     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 77,966\n",
      "Trainable params: 77,960\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,32,3)))\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(32,32,3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(4,4)))\n",
    "model.add(Conv2D(32, (5, 5), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(4,4)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness and pixel shift variations. These is implemented with a ImageDataGenerator.\n",
    "\n",
    "\n",
    "The training is splitted into two steps:\n",
    "1. Variation of the brightness only\n",
    "2. Variation of brightness and Pixel Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Brigthness scattering only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "386/386 [==============================] - 20s 52ms/step - loss: 0.1714 - accuracy: 0.8450 - val_loss: 0.0124 - val_accuracy: 0.9767\n",
      "Epoch 2/30\n",
      "386/386 [==============================] - 20s 53ms/step - loss: 0.0154 - accuracy: 0.9647 - val_loss: 0.0203 - val_accuracy: 0.9831\n",
      "Epoch 3/30\n",
      "386/386 [==============================] - 20s 52ms/step - loss: 0.0105 - accuracy: 0.9643 - val_loss: 0.0052 - val_accuracy: 0.9546\n",
      "Epoch 4/30\n",
      "386/386 [==============================] - 22s 57ms/step - loss: 0.0077 - accuracy: 0.9711 - val_loss: 0.0063 - val_accuracy: 0.9767\n",
      "Epoch 5/30\n",
      "386/386 [==============================] - 20s 53ms/step - loss: 0.0057 - accuracy: 0.9724 - val_loss: 0.0050 - val_accuracy: 0.9922\n",
      "Epoch 6/30\n",
      "386/386 [==============================] - 22s 56ms/step - loss: 0.0042 - accuracy: 0.9718 - val_loss: 0.0064 - val_accuracy: 0.9883\n",
      "Epoch 7/30\n",
      "386/386 [==============================] - 21s 54ms/step - loss: 0.0037 - accuracy: 0.9754 - val_loss: 0.0028 - val_accuracy: 0.9870\n",
      "Epoch 8/30\n",
      "386/386 [==============================] - 22s 57ms/step - loss: 0.0029 - accuracy: 0.9734 - val_loss: 0.0027 - val_accuracy: 0.9857\n",
      "Epoch 9/30\n",
      "386/386 [==============================] - 19s 50ms/step - loss: 0.0024 - accuracy: 0.9809 - val_loss: 0.0017 - val_accuracy: 0.9883\n",
      "Epoch 10/30\n",
      "386/386 [==============================] - 20s 51ms/step - loss: 0.0021 - accuracy: 0.9792 - val_loss: 0.0023 - val_accuracy: 0.9767\n",
      "Epoch 11/30\n",
      " 62/386 [===>..........................] - ETA: 17s - loss: 0.0018 - accuracy: 0.9839"
     ]
    }
   ],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 30\n",
    "Shift_Range = 0\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "train_iterator = datagen.flow(X_train, y_train, batch_size=Batch_Size)\n",
    "validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "\n",
    "history = model.fit_generator(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Brigthness and Pixel Shift scattering\n",
    "Here a higher number of epochs is used to reach the minimum loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 80\n",
    "Shift_Range = 3\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "train_iterator = datagen.flow(X_train, y_train, batch_size=Batch_Size)\n",
    "validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "\n",
    "history = model.fit_generator(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Learing results (Step 1 & Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "\n",
    "plt.semilogy(loss_ges)\n",
    "plt.semilogy(val_loss_ges)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* The evaluation takes the periodic character of the results into account (dev1 ... dev2).\n",
    "* Images, that have a bigger deviation as the parameter \"deviation_max_list\" are printed in a list to check the picture and labeling itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='data_resize_all'\n",
    "#Input_dir='test_result'\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "res = []\n",
    "i = 0\n",
    "deviation_max_list = 0.03\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = (float(base[0:3])) / 10\n",
    "    target_sin = math.sin(target * math.pi * 2)\n",
    "    target_cos = math.cos(target * math.pi * 2)\n",
    "\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,32,3])\n",
    "    classes = model.predict(img)\n",
    "    \n",
    "    out_sin = classes[0][0]  \n",
    "    out_cos = classes[0][1]\n",
    "    out_target = (np.arctan2(out_sin, out_cos)/(2*math.pi)) % 1\n",
    "\n",
    "    dev_sin = target_sin - out_sin\n",
    "    dev_cos = target_cos - out_cos\n",
    "    dev_target = target - out_target\n",
    "    \n",
    "    if abs(dev_target + 1) < abs(dev_target):\n",
    "        out_target = out_target - 1\n",
    "        dev_target = target - out_target\n",
    "    else:\n",
    "        if abs(dev_target - 1) < abs(dev_target):\n",
    "            out_target = out_target + 1\n",
    "            dev_target = target - out_target\n",
    "               \n",
    "    res.append(np.array([target, out_target, dev_target, out_sin, out_cos, i]))\n",
    "    if abs(dev_target) > deviation_max_list:\n",
    "        print(aktfile + \" \" + str(target) + \" \" + str(out_target) +  \" \" + str(dev_target))\n",
    "    i+=1\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,3])\n",
    "plt.plot(res[:,4])\n",
    "plt.title('Result')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['sin', 'cos'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation from Expected Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,2])\n",
    "plt.title('Deviation')\n",
    "plt.ylabel('Deviation from expected value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Deviation'], loc='upper left')\n",
    "#plt.ylim(-0.3, 0.3)\n",
    "plt.show()\n",
    "\n",
    "statistic = np.array([np.mean(res[:,2]), np.std(res[:,2]), np.min(res[:,2]), np.max(res[:,2])])\n",
    "print(statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CNN_Analog-Readout_Version-5.0.0.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
