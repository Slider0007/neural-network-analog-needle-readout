{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to extract the needle position of an analog needle device.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "Version = \"7.0.0\"                      # Used for tflite Filename\n",
    "Training_Percentage = 0.2              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 100\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History \n",
    "import math\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Picture size must be 32x32 with 3 color channels (RGB)\n",
    "* The filename contains the informations needed for training in the first 3 digits::\n",
    "* Typical filename: \n",
    "    * x.y-zzzz.jpg \n",
    "    * e.g. \"4.6_Lfd-1406_zeiger3_2019-06-02T050011\"\n",
    "\n",
    "|Place holder | Meaning                     | Usage        |\n",
    "|------------- |-----------------------------|--------------|\n",
    "| **x.y**          | readout value               | **to be learned** |\n",
    "| zzzz        | additional information              | not needed   |\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected output for each image in the corresponding y_data[]\n",
    "    * The periodic nature is reflected in a **sin/cos coding**, which allows to restore the angle/counter value with an arctan later on.\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) as the filenames are on order due to the encoding of the expected analog readout in the filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4927, 32, 32, 3)\n",
      "(4927, 2)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='data_resize_all'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    test_image = np.reshape(test_image, (32,32,3))\n",
    "    base = os.path.basename(aktfile)\n",
    "    target_number = (float(base[0:3])) / 10\n",
    "    target_sin = math.sin(target_number * math.pi * 2)\n",
    "    target_cos = math.cos(target_number * math.pi * 2)\n",
    "\n",
    "    x_data.append(test_image)\n",
    "    zw = np.array([target_sin, target_cos])\n",
    "    y_data.append(zw)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 32, 3)\n",
    "* Shape of the output layer: (2) - sin and cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 32)          51232     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 77,966\n",
      "Trainable params: 77,960\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,32,3)))\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(32,32,3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(4,4)))\n",
    "model.add(Conv2D(32, (5, 5), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(4,4)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness and pixel shift variations. These is implemented with a ImageDataGenerator.\n",
    "\n",
    "\n",
    "The training is splitted into two steps:\n",
    "1. Variation of the brightness only\n",
    "2. Variation of brightness and Pixel Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Brigthness scattering only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-506eaab5eeb9>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 0.1359 - accuracy: 0.8612 - val_loss: 0.0583 - val_accuracy: 0.9604\n",
      "Epoch 2/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0168 - accuracy: 0.9665 - val_loss: 0.0066 - val_accuracy: 0.9807\n",
      "Epoch 3/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0096 - accuracy: 0.9736 - val_loss: 0.0073 - val_accuracy: 0.9767\n",
      "Epoch 4/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0059 - accuracy: 0.9799 - val_loss: 0.0141 - val_accuracy: 0.9422\n",
      "Epoch 5/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0042 - accuracy: 0.9825 - val_loss: 0.0027 - val_accuracy: 0.9909\n",
      "Epoch 6/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 0.0030 - accuracy: 0.9836 - val_loss: 0.0020 - val_accuracy: 0.9878\n",
      "Epoch 7/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0024 - accuracy: 0.9876 - val_loss: 0.0017 - val_accuracy: 0.9858\n",
      "Epoch 8/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0022 - accuracy: 0.9876 - val_loss: 0.0020 - val_accuracy: 0.9828\n",
      "Epoch 9/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0018 - accuracy: 0.9890 - val_loss: 0.0013 - val_accuracy: 0.9878\n",
      "Epoch 10/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0016 - accuracy: 0.9894 - val_loss: 0.0019 - val_accuracy: 0.9929\n",
      "Epoch 11/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0015 - accuracy: 0.9925 - val_loss: 0.0012 - val_accuracy: 0.9919\n",
      "Epoch 12/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0014 - accuracy: 0.9899 - val_loss: 9.2964e-04 - val_accuracy: 0.9949\n",
      "Epoch 13/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0013 - accuracy: 0.9905 - val_loss: 8.1517e-04 - val_accuracy: 0.9939\n",
      "Epoch 14/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0011 - accuracy: 0.9939 - val_loss: 9.3859e-04 - val_accuracy: 0.9949\n",
      "Epoch 15/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0011 - accuracy: 0.9935 - val_loss: 9.5134e-04 - val_accuracy: 0.9970\n",
      "Epoch 16/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0010 - accuracy: 0.9931 - val_loss: 7.8885e-04 - val_accuracy: 0.9970\n",
      "Epoch 17/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 9.6396e-04 - accuracy: 0.9929 - val_loss: 9.3000e-04 - val_accuracy: 0.9970\n",
      "Epoch 18/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 8.6187e-04 - accuracy: 0.9933 - val_loss: 8.7879e-04 - val_accuracy: 0.9939\n",
      "Epoch 19/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 8.6485e-04 - accuracy: 0.9925 - val_loss: 6.2470e-04 - val_accuracy: 0.9970\n",
      "Epoch 20/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 8.1056e-04 - accuracy: 0.9931 - val_loss: 0.0012 - val_accuracy: 0.9990\n",
      "Epoch 21/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.6547e-04 - accuracy: 0.9953 - val_loss: 4.9907e-04 - val_accuracy: 0.9959\n",
      "Epoch 22/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.5345e-04 - accuracy: 0.9933 - val_loss: 5.4494e-04 - val_accuracy: 0.9959\n",
      "Epoch 23/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.0374e-04 - accuracy: 0.9937 - val_loss: 4.6086e-04 - val_accuracy: 0.9980\n",
      "Epoch 24/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.1461e-04 - accuracy: 0.9939 - val_loss: 5.7125e-04 - val_accuracy: 0.9949\n",
      "Epoch 25/30\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 6.6438e-04 - accuracy: 0.9931 - val_loss: 9.9130e-04 - val_accuracy: 0.9980\n",
      "Epoch 26/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.4590e-04 - accuracy: 0.9955 - val_loss: 4.4607e-04 - val_accuracy: 0.9970\n",
      "Epoch 27/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.4111e-04 - accuracy: 0.9957 - val_loss: 8.5373e-04 - val_accuracy: 0.9970\n",
      "Epoch 28/30\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 5.9562e-04 - accuracy: 0.9968 - val_loss: 4.5205e-04 - val_accuracy: 0.9970\n",
      "Epoch 29/30\n",
      "616/616 [==============================] - 7s 11ms/step - loss: 5.8684e-04 - accuracy: 0.9955 - val_loss: 8.2504e-04 - val_accuracy: 0.9919\n",
      "Epoch 30/30\n",
      "616/616 [==============================] - 7s 11ms/step - loss: 5.7743e-04 - accuracy: 0.9953 - val_loss: 5.5824e-04 - val_accuracy: 0.9949\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 30\n",
    "Shift_Range = 0\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Brigthness and Pixel Shift scattering\n",
    "Here a higher number of epochs is used to reach the minimum loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 0.0441 - accuracy: 0.9399 - val_loss: 0.0102 - val_accuracy: 0.9807\n",
      "Epoch 2/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 0.0088 - accuracy: 0.9761 - val_loss: 0.0048 - val_accuracy: 0.9888\n",
      "Epoch 3/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0057 - accuracy: 0.9834 - val_loss: 0.0071 - val_accuracy: 0.9757\n",
      "Epoch 4/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0041 - accuracy: 0.9813 - val_loss: 0.0040 - val_accuracy: 0.9868\n",
      "Epoch 5/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0035 - accuracy: 0.9834 - val_loss: 0.0024 - val_accuracy: 0.9878\n",
      "Epoch 6/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0031 - accuracy: 0.9860 - val_loss: 0.0029 - val_accuracy: 0.9909\n",
      "Epoch 7/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0029 - accuracy: 0.9876 - val_loss: 0.0019 - val_accuracy: 0.9959\n",
      "Epoch 8/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0025 - accuracy: 0.9876 - val_loss: 0.0021 - val_accuracy: 0.9878\n",
      "Epoch 9/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0022 - accuracy: 0.9896 - val_loss: 0.0014 - val_accuracy: 0.9909\n",
      "Epoch 10/160\n",
      "616/616 [==============================] - 8s 14ms/step - loss: 0.0020 - accuracy: 0.9890 - val_loss: 0.0014 - val_accuracy: 0.9919\n",
      "Epoch 11/160\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.0019 - accuracy: 0.9903 - val_loss: 0.0016 - val_accuracy: 0.9949\n",
      "Epoch 12/160\n",
      "616/616 [==============================] - 8s 14ms/step - loss: 0.0017 - accuracy: 0.9915 - val_loss: 0.0024 - val_accuracy: 0.9878\n",
      "Epoch 13/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0017 - accuracy: 0.9894 - val_loss: 0.0013 - val_accuracy: 0.9919\n",
      "Epoch 14/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0016 - accuracy: 0.9896 - val_loss: 0.0012 - val_accuracy: 0.9939\n",
      "Epoch 15/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0015 - accuracy: 0.9919 - val_loss: 0.0012 - val_accuracy: 0.9929\n",
      "Epoch 16/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0014 - accuracy: 0.9911 - val_loss: 0.0014 - val_accuracy: 0.9858\n",
      "Epoch 17/160\n",
      "616/616 [==============================] - 10s 15ms/step - loss: 0.0014 - accuracy: 0.9905 - val_loss: 0.0012 - val_accuracy: 0.9959\n",
      "Epoch 18/160\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.0013 - accuracy: 0.9933 - val_loss: 0.0012 - val_accuracy: 0.9909\n",
      "Epoch 19/160\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.0013 - accuracy: 0.9886 - val_loss: 0.0012 - val_accuracy: 0.9929\n",
      "Epoch 20/160\n",
      "616/616 [==============================] - 9s 15ms/step - loss: 0.0013 - accuracy: 0.9903 - val_loss: 0.0012 - val_accuracy: 0.9929\n",
      "Epoch 21/160\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.0012 - accuracy: 0.9931 - val_loss: 0.0010 - val_accuracy: 0.9899\n",
      "Epoch 22/160\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 0.0012 - accuracy: 0.9917 - val_loss: 0.0010 - val_accuracy: 0.9929\n",
      "Epoch 23/160\n",
      "616/616 [==============================] - 8s 14ms/step - loss: 0.0012 - accuracy: 0.9917 - val_loss: 9.6105e-04 - val_accuracy: 0.9949\n",
      "Epoch 24/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0011 - accuracy: 0.9913 - val_loss: 0.0010 - val_accuracy: 0.9939\n",
      "Epoch 25/160\n",
      "616/616 [==============================] - 8s 14ms/step - loss: 0.0011 - accuracy: 0.9927 - val_loss: 9.6376e-04 - val_accuracy: 0.9919\n",
      "Epoch 26/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 0.0011 - accuracy: 0.9925 - val_loss: 8.4350e-04 - val_accuracy: 0.9949\n",
      "Epoch 27/160\n",
      "616/616 [==============================] - 10s 16ms/step - loss: 0.0010 - accuracy: 0.9929 - val_loss: 9.3301e-04 - val_accuracy: 0.9980\n",
      "Epoch 28/160\n",
      "616/616 [==============================] - 13s 21ms/step - loss: 0.0010 - accuracy: 0.9921 - val_loss: 7.1570e-04 - val_accuracy: 0.9949\n",
      "Epoch 29/160\n",
      "616/616 [==============================] - 12s 20ms/step - loss: 9.2492e-04 - accuracy: 0.9937 - val_loss: 9.6588e-04 - val_accuracy: 0.9939\n",
      "Epoch 30/160\n",
      "616/616 [==============================] - 13s 21ms/step - loss: 0.0010 - accuracy: 0.9917 - val_loss: 7.5139e-04 - val_accuracy: 0.9949\n",
      "Epoch 31/160\n",
      "616/616 [==============================] - 14s 22ms/step - loss: 9.4989e-04 - accuracy: 0.9935 - val_loss: 9.6220e-04 - val_accuracy: 0.9959\n",
      "Epoch 32/160\n",
      "616/616 [==============================] - 15s 24ms/step - loss: 9.6135e-04 - accuracy: 0.9947 - val_loss: 9.3493e-04 - val_accuracy: 0.9858\n",
      "Epoch 33/160\n",
      "616/616 [==============================] - 16s 25ms/step - loss: 9.1261e-04 - accuracy: 0.9915 - val_loss: 9.7652e-04 - val_accuracy: 0.9909\n",
      "Epoch 34/160\n",
      "616/616 [==============================] - 16s 26ms/step - loss: 8.9645e-04 - accuracy: 0.9939 - val_loss: 0.0012 - val_accuracy: 0.9888\n",
      "Epoch 35/160\n",
      "616/616 [==============================] - 16s 26ms/step - loss: 8.4929e-04 - accuracy: 0.9917 - val_loss: 8.3577e-04 - val_accuracy: 0.9919\n",
      "Epoch 36/160\n",
      "616/616 [==============================] - 15s 24ms/step - loss: 8.8536e-04 - accuracy: 0.9939 - val_loss: 8.0530e-04 - val_accuracy: 0.9970\n",
      "Epoch 37/160\n",
      "616/616 [==============================] - 15s 24ms/step - loss: 8.3536e-04 - accuracy: 0.9937 - val_loss: 8.7387e-04 - val_accuracy: 0.9939s: 8.3\n",
      "Epoch 38/160\n",
      "616/616 [==============================] - 16s 25ms/step - loss: 8.2426e-04 - accuracy: 0.9943 - val_loss: 8.3929e-04 - val_accuracy: 0.9899\n",
      "Epoch 39/160\n",
      "616/616 [==============================] - 12s 19ms/step - loss: 8.6208e-04 - accuracy: 0.9931 - val_loss: 7.4659e-04 - val_accuracy: 0.9929\n",
      "Epoch 40/160\n",
      "616/616 [==============================] - 9s 14ms/step - loss: 8.3202e-04 - accuracy: 0.9929 - val_loss: 9.0576e-04 - val_accuracy: 0.9939\n",
      "Epoch 41/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 7.8136e-04 - accuracy: 0.9933 - val_loss: 6.6893e-04 - val_accuracy: 0.9929\n",
      "Epoch 42/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.9744e-04 - accuracy: 0.9913 - val_loss: 7.7185e-04 - val_accuracy: 0.9929\n",
      "Epoch 43/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 7.7635e-04 - accuracy: 0.9943 - val_loss: 7.5859e-04 - val_accuracy: 0.9970\n",
      "Epoch 44/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 7.6965e-04 - accuracy: 0.9929 - val_loss: 8.0540e-04 - val_accuracy: 0.9970\n",
      "Epoch 45/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 7.9027e-04 - accuracy: 0.9935 - val_loss: 9.1360e-04 - val_accuracy: 0.9929\n",
      "Epoch 46/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.1651e-04 - accuracy: 0.9949 - val_loss: 5.5766e-04 - val_accuracy: 0.9980\n",
      "Epoch 47/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 7.3186e-04 - accuracy: 0.9945 - val_loss: 6.2843e-04 - val_accuracy: 0.9980\n",
      "Epoch 48/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.3983e-04 - accuracy: 0.9951 - val_loss: 6.4476e-04 - val_accuracy: 0.9980\n",
      "Epoch 49/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.3214e-04 - accuracy: 0.9961 - val_loss: 6.4483e-04 - val_accuracy: 0.9949\n",
      "Epoch 50/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 6.8831e-04 - accuracy: 0.9931 - val_loss: 7.1217e-04 - val_accuracy: 0.9959\n",
      "Epoch 51/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 7.2661e-04 - accuracy: 0.9955 - val_loss: 6.6772e-04 - val_accuracy: 0.9990\n",
      "Epoch 52/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 7.0732e-04 - accuracy: 0.9935 - val_loss: 8.0650e-04 - val_accuracy: 0.9939\n",
      "Epoch 53/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 7.0324e-04 - accuracy: 0.9945 - val_loss: 7.3367e-04 - val_accuracy: 0.9929\n",
      "Epoch 54/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 6.7237e-04 - accuracy: 0.9945 - val_loss: 8.6535e-04 - val_accuracy: 0.9959\n",
      "Epoch 55/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.7008e-04 - accuracy: 0.9939 - val_loss: 6.6304e-04 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.8400e-04 - accuracy: 0.9933 - val_loss: 6.0562e-04 - val_accuracy: 0.9949\n",
      "Epoch 57/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.7817e-04 - accuracy: 0.9955 - val_loss: 6.2870e-04 - val_accuracy: 0.9929\n",
      "Epoch 58/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.7122e-04 - accuracy: 0.9935 - val_loss: 7.2604e-04 - val_accuracy: 0.9980\n",
      "Epoch 59/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.5373e-04 - accuracy: 0.9947 - val_loss: 6.3255e-04 - val_accuracy: 0.9970\n",
      "Epoch 60/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.7347e-04 - accuracy: 0.9953 - val_loss: 6.0999e-04 - val_accuracy: 0.9959\n",
      "Epoch 61/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.1842e-04 - accuracy: 0.9945 - val_loss: 7.9859e-04 - val_accuracy: 0.9959\n",
      "Epoch 62/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.2597e-04 - accuracy: 0.9931 - val_loss: 6.3293e-04 - val_accuracy: 0.9949\n",
      "Epoch 63/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.4918e-04 - accuracy: 0.9941 - val_loss: 5.8044e-04 - val_accuracy: 0.9949\n",
      "Epoch 64/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.3231e-04 - accuracy: 0.9947 - val_loss: 5.7129e-04 - val_accuracy: 0.9939\n",
      "Epoch 65/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.2155e-04 - accuracy: 0.9931 - val_loss: 5.3104e-04 - val_accuracy: 0.9970\n",
      "Epoch 66/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.0772e-04 - accuracy: 0.9947 - val_loss: 7.1503e-04 - val_accuracy: 0.9878\n",
      "Epoch 67/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 6.0298e-04 - accuracy: 0.9955 - val_loss: 6.1490e-04 - val_accuracy: 0.9959\n",
      "Epoch 68/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 5.8871e-04 - accuracy: 0.9959 - val_loss: 5.0062e-04 - val_accuracy: 0.9929\n",
      "Epoch 69/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 6.0475e-04 - accuracy: 0.9947 - val_loss: 6.0182e-04 - val_accuracy: 0.9939\n",
      "Epoch 70/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 6.1549e-04 - accuracy: 0.9949 - val_loss: 6.5992e-04 - val_accuracy: 0.9970\n",
      "Epoch 71/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.9192e-04 - accuracy: 0.9951 - val_loss: 5.4373e-04 - val_accuracy: 0.9980\n",
      "Epoch 72/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 5.9328e-04 - accuracy: 0.9919 - val_loss: 5.4282e-04 - val_accuracy: 0.9949\n",
      "Epoch 73/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.8992e-04 - accuracy: 0.9949 - val_loss: 4.5017e-04 - val_accuracy: 0.9959\n",
      "Epoch 74/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 5.8196e-04 - accuracy: 0.9951 - val_loss: 5.6521e-04 - val_accuracy: 0.9959\n",
      "Epoch 75/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.6186e-04 - accuracy: 0.9945 - val_loss: 5.6263e-04 - val_accuracy: 0.9970\n",
      "Epoch 76/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 5.6909e-04 - accuracy: 0.9968 - val_loss: 4.4005e-04 - val_accuracy: 0.9990\n",
      "Epoch 77/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.4853e-04 - accuracy: 0.9951 - val_loss: 4.9688e-04 - val_accuracy: 0.9949\n",
      "Epoch 78/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.6468e-04 - accuracy: 0.9949 - val_loss: 4.0539e-04 - val_accuracy: 0.9990\n",
      "Epoch 79/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 5.6239e-04 - accuracy: 0.9945 - val_loss: 5.7459e-04 - val_accuracy: 0.9980\n",
      "Epoch 80/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.6087e-04 - accuracy: 0.9951 - val_loss: 4.8364e-04 - val_accuracy: 0.9949\n",
      "Epoch 81/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.5191e-04 - accuracy: 0.9949 - val_loss: 4.5108e-04 - val_accuracy: 0.9959\n",
      "Epoch 82/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 5.7052e-04 - accuracy: 0.9961 - val_loss: 4.3183e-04 - val_accuracy: 0.9929\n",
      "Epoch 83/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.3464e-04 - accuracy: 0.9947 - val_loss: 5.7057e-04 - val_accuracy: 0.9959\n",
      "Epoch 84/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.5145e-04 - accuracy: 0.9963 - val_loss: 4.9862e-04 - val_accuracy: 0.9980\n",
      "Epoch 85/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.8075e-04 - accuracy: 0.9949 - val_loss: 4.3909e-04 - val_accuracy: 0.9959\n",
      "Epoch 86/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.5732e-04 - accuracy: 0.9957 - val_loss: 5.9900e-04 - val_accuracy: 0.9970\n",
      "Epoch 87/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.2803e-04 - accuracy: 0.9961 - val_loss: 4.7548e-04 - val_accuracy: 0.9990\n",
      "Epoch 88/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.1514e-04 - accuracy: 0.9937 - val_loss: 8.3652e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.1892e-04 - accuracy: 0.9963 - val_loss: 4.2789e-04 - val_accuracy: 0.9980\n",
      "Epoch 90/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.1323e-04 - accuracy: 0.9965 - val_loss: 5.0763e-04 - val_accuracy: 0.9980\n",
      "Epoch 91/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.1995e-04 - accuracy: 0.9970 - val_loss: 5.3380e-04 - val_accuracy: 0.9970\n",
      "Epoch 92/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.2973e-04 - accuracy: 0.9953 - val_loss: 5.9626e-04 - val_accuracy: 0.9959\n",
      "Epoch 93/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.0978e-04 - accuracy: 0.9953 - val_loss: 4.1531e-04 - val_accuracy: 0.9980\n",
      "Epoch 94/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.1032e-04 - accuracy: 0.9951 - val_loss: 5.1461e-04 - val_accuracy: 0.9939\n",
      "Epoch 95/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.9827e-04 - accuracy: 0.9953 - val_loss: 4.7504e-04 - val_accuracy: 0.9980\n",
      "Epoch 96/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.9766e-04 - accuracy: 0.9949 - val_loss: 5.1888e-04 - val_accuracy: 0.9949\n",
      "Epoch 97/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.0108e-04 - accuracy: 0.9961 - val_loss: 4.7037e-04 - val_accuracy: 0.9970\n",
      "Epoch 98/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.0080e-04 - accuracy: 0.9957 - val_loss: 5.8050e-04 - val_accuracy: 0.9990\n",
      "Epoch 99/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 5.0781e-04 - accuracy: 0.9951 - val_loss: 4.0748e-04 - val_accuracy: 0.9980\n",
      "Epoch 100/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.7702e-04 - accuracy: 0.9951 - val_loss: 4.5518e-04 - val_accuracy: 0.9939\n",
      "Epoch 101/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.8634e-04 - accuracy: 0.9957 - val_loss: 5.2026e-04 - val_accuracy: 0.9949\n",
      "Epoch 102/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.8417e-04 - accuracy: 0.9949 - val_loss: 4.6542e-04 - val_accuracy: 0.9959\n",
      "Epoch 103/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.7824e-04 - accuracy: 0.9968 - val_loss: 4.6876e-04 - val_accuracy: 0.9970\n",
      "Epoch 104/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.7115e-04 - accuracy: 0.9965 - val_loss: 4.8930e-04 - val_accuracy: 0.9949\n",
      "Epoch 105/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.8720e-04 - accuracy: 0.9955 - val_loss: 4.1028e-04 - val_accuracy: 0.9970\n",
      "Epoch 106/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.7918e-04 - accuracy: 0.9965 - val_loss: 3.9500e-04 - val_accuracy: 0.9959\n",
      "Epoch 107/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.6126e-04 - accuracy: 0.9955 - val_loss: 5.0308e-04 - val_accuracy: 0.9970\n",
      "Epoch 108/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.8186e-04 - accuracy: 0.9961 - val_loss: 3.5813e-04 - val_accuracy: 0.9959\n",
      "Epoch 109/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616/616 [==============================] - 8s 12ms/step - loss: 4.6506e-04 - accuracy: 0.9965 - val_loss: 3.5665e-04 - val_accuracy: 0.9980\n",
      "Epoch 110/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.7161e-04 - accuracy: 0.9961 - val_loss: 4.0235e-04 - val_accuracy: 0.9959\n",
      "Epoch 111/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5681e-04 - accuracy: 0.9965 - val_loss: 4.4387e-04 - val_accuracy: 0.9959\n",
      "Epoch 112/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.4438e-04 - accuracy: 0.9959 - val_loss: 4.3951e-04 - val_accuracy: 1.0000\n",
      "Epoch 113/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5504e-04 - accuracy: 0.9963 - val_loss: 6.1104e-04 - val_accuracy: 0.9939\n",
      "Epoch 114/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.3939e-04 - accuracy: 0.9953 - val_loss: 4.1800e-04 - val_accuracy: 0.9980\n",
      "Epoch 115/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5393e-04 - accuracy: 0.9955 - val_loss: 4.7735e-04 - val_accuracy: 0.9959\n",
      "Epoch 116/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5312e-04 - accuracy: 0.9953 - val_loss: 3.3803e-04 - val_accuracy: 0.9980\n",
      "Epoch 117/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5373e-04 - accuracy: 0.9953 - val_loss: 4.6983e-04 - val_accuracy: 0.9980\n",
      "Epoch 118/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5462e-04 - accuracy: 0.9947 - val_loss: 3.9556e-04 - val_accuracy: 0.9980\n",
      "Epoch 119/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5705e-04 - accuracy: 0.9965 - val_loss: 6.4103e-04 - val_accuracy: 0.9949\n",
      "Epoch 120/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.5132e-04 - accuracy: 0.9951 - val_loss: 3.6155e-04 - val_accuracy: 0.9990\n",
      "Epoch 121/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.4115e-04 - accuracy: 0.9947 - val_loss: 3.4924e-04 - val_accuracy: 0.9990\n",
      "Epoch 122/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.4447e-04 - accuracy: 0.9953 - val_loss: 4.1030e-04 - val_accuracy: 0.9990\n",
      "Epoch 123/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.3831e-04 - accuracy: 0.9970 - val_loss: 4.2993e-04 - val_accuracy: 0.9909\n",
      "Epoch 124/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.3517e-04 - accuracy: 0.9959 - val_loss: 3.8791e-04 - val_accuracy: 0.9970\n",
      "Epoch 125/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.3096e-04 - accuracy: 0.9955 - val_loss: 4.0483e-04 - val_accuracy: 0.9980\n",
      "Epoch 126/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.4203e-04 - accuracy: 0.9953 - val_loss: 3.3882e-04 - val_accuracy: 0.9990\n",
      "Epoch 127/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.4663e-04 - accuracy: 0.9959 - val_loss: 3.8113e-04 - val_accuracy: 0.9980\n",
      "Epoch 128/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.3798e-04 - accuracy: 0.9968 - val_loss: 5.0495e-04 - val_accuracy: 0.9970\n",
      "Epoch 129/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 4.4700e-04 - accuracy: 0.9957 - val_loss: 5.2516e-04 - val_accuracy: 0.9990\n",
      "Epoch 130/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 4.3603e-04 - accuracy: 0.9939 - val_loss: 4.3615e-04 - val_accuracy: 0.9970\n",
      "Epoch 131/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 4.2106e-04 - accuracy: 0.9965 - val_loss: 3.7282e-04 - val_accuracy: 0.9959\n",
      "Epoch 132/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 4.3158e-04 - accuracy: 0.9959 - val_loss: 5.0052e-04 - val_accuracy: 0.9990\n",
      "Epoch 133/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 4.2007e-04 - accuracy: 0.9949 - val_loss: 3.4900e-04 - val_accuracy: 0.9929\n",
      "Epoch 134/160\n",
      "616/616 [==============================] - 8s 12ms/step - loss: 4.1000e-04 - accuracy: 0.9963 - val_loss: 5.1924e-04 - val_accuracy: 0.9939\n",
      "Epoch 135/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.3077e-04 - accuracy: 0.9961 - val_loss: 4.4761e-04 - val_accuracy: 0.9980\n",
      "Epoch 136/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 4.1564e-04 - accuracy: 0.9959 - val_loss: 4.3585e-04 - val_accuracy: 0.9970\n",
      "Epoch 137/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.2316e-04 - accuracy: 0.9980 - val_loss: 3.9451e-04 - val_accuracy: 0.9939\n",
      "Epoch 138/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.2353e-04 - accuracy: 0.9963 - val_loss: 4.6297e-04 - val_accuracy: 0.9990\n",
      "Epoch 139/160\n",
      "616/616 [==============================] - 7s 12ms/step - loss: 4.0398e-04 - accuracy: 0.9978 - val_loss: 3.5776e-04 - val_accuracy: 0.9949\n",
      "Epoch 140/160\n",
      "616/616 [==============================] - 8s 14ms/step - loss: 4.3537e-04 - accuracy: 0.9982 - val_loss: 4.1488e-04 - val_accuracy: 0.9980\n",
      "Epoch 141/160\n",
      "616/616 [==============================] - 8s 13ms/step - loss: 4.1969e-04 - accuracy: 0.9955 - val_loss: 3.4525e-04 - val_accuracy: 0.9990\n",
      "Epoch 142/160\n",
      "128/616 [=====>........................] - ETA: 5s - loss: 3.7336e-04 - accuracy: 0.9951"
     ]
    }
   ],
   "source": [
    "Batch_Size = 8\n",
    "Epoch_Anz = 160\n",
    "Shift_Range = 3\n",
    "Brightness_Range = 0.3\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], height_shift_range=[-Shift_Range,Shift_Range],brightness_range=[1-Brightness_Range,1+Brightness_Range])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit_generator(train_iterator, epochs = Epoch_Anz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Learing results (Step 1 & Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.semilogy(loss_ges)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* The evaluation takes the periodic character of the results into account (dev1 ... dev2).\n",
    "* Images, that have a bigger deviation as the parameter \"deviation_max_list\" are printed in a list to check the picture and labeling itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dir='data_resize_all'\n",
    "#Input_dir='test_result'\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "res = []\n",
    "stat_Anz = []\n",
    "stat_Abweichung = [100]\n",
    "i = 0\n",
    "deviation_max_list = 0.05\n",
    "\n",
    "for i in range(100):\n",
    "    stat_Anz.append(0)\n",
    "    stat_Abweichung.append(0)\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = (float(base[0:3])) / 10\n",
    "    \n",
    "    target_sin = math.sin(target * math.pi * 2)\n",
    "    target_cos = math.cos(target * math.pi * 2)\n",
    "\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,32,3])\n",
    "    classes = model.predict(img)\n",
    "    \n",
    "    out_sin = classes[0][0]  \n",
    "    out_cos = classes[0][1]\n",
    "    out_target = (np.arctan2(out_sin, out_cos)/(2*math.pi)) % 1\n",
    "\n",
    "    dev_sin = target_sin - out_sin\n",
    "    dev_cos = target_cos - out_cos\n",
    "    dev_target = target - out_target\n",
    "    \n",
    "    if abs(dev_target + 1) < abs(dev_target):\n",
    "        out_target = out_target - 1\n",
    "        dev_target = target - out_target\n",
    "    else:\n",
    "        if abs(dev_target - 1) < abs(dev_target):\n",
    "            out_target = out_target + 1\n",
    "            dev_target = target - out_target\n",
    "            \n",
    "    target_int = int ((float(base[0:3])) * 10)\n",
    "    stat_Abweichung[target_int] = stat_Abweichung[target_int] + dev_target  \n",
    "    stat_Anz[target_int] = stat_Anz[target_int] + 1\n",
    "               \n",
    "    res.append(np.array([target, out_target, dev_target, out_sin, out_cos, i]))\n",
    "    if abs(dev_target) > deviation_max_list:\n",
    "        print(aktfile + \" \" + str(target) + \" \" + str(out_target) +  \" \" + str(dev_target))\n",
    "    i+=1\n",
    "    \n",
    "for i in range(100):\n",
    "    stat_Abweichung[i] = stat_Abweichung[i] / stat_Anz[i]\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,3])\n",
    "plt.plot(res[:,4])\n",
    "plt.title('Result')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['sin', 'cos'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stat_Abweichung)\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stat_Anz)\n",
    "plt.title('Result')\n",
    "plt.ylabel('Counter Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Orginal', 'Prediction'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation from Expected Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res[:,2])\n",
    "plt.title('Deviation')\n",
    "plt.ylabel('Deviation from expected value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['Deviation'], loc='upper left')\n",
    "#plt.ylim(-0.3, 0.3)\n",
    "plt.show()\n",
    "\n",
    "statistic = np.array([np.mean(res[:,2]), np.std(res[:,2]), np.min(res[:,2]), np.max(res[:,2])])\n",
    "print(statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = \"CNN_Analog-Readout_Version_\" + Version\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = \"CNN_Analog-Readout_Quantized_Version_\" + Version\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(500):\n",
    "      data = np.random.rand(1, 32, 32, 3) * 255\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter2.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter2.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
